{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "n-C5u4NgKWah",
      "metadata": {
        "id": "n-C5u4NgKWah"
      },
      "source": [
        "# QWEN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "YtOJd-7kmEXw",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 890,
          "referenced_widgets": [
            "f1fe27e3860c4cf380107fb67d43e2f8",
            "415f1d3040fb4902aeb231047ac7fa70",
            "307a489504ef401a9ac97224e10a66bc",
            "28a71f72e8b54221a4af5863f5e8597b",
            "0b98f7417dff428fbba978a6307ced56",
            "e3be9576eebf46fba1eab3d0384a8a80",
            "4eb63505ad5d4248987bc9d1ee304069",
            "fbcd4e8cb8ab48d69d2c8f28f01ed159",
            "321ffc2d757443b48e6988788de84f6e",
            "018b70395c624efc8e80139ce7dacd21",
            "35b504a135fb4f62b5e4fa02779a8e8a"
          ]
        },
        "id": "YtOJd-7kmEXw",
        "outputId": "9f53d217-5cff-4289-9d85-54a1972b3114"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Извлечённый текст:\n",
            "Блог / Новости Возрождение лютоволков из «Игры престолов»: научный прорыв Полина Недашковская 07 мая, 2025 • 2 мин • 155 Копировать ссылку Telegram VK WhatsApp Биотехнологическая компания Colossal Biosciences из Далласа совершила прорыв в области возрождения вымерших видов животных, воссоздав ужасных волков (dire wolves), известных широкой аудитории как «лютоволки» из «Игры престолов» . Процесс был долгим и сложным, но в итоге ученые смогли вернуть к жизни этот вид, вымерший более 12 тысяч лет н...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример аннотаций BERT:\n",
            "[{'entity': 'B-PER', 'score': np.float32(0.9994863), 'index': 26, 'word': 'Пол', 'start': 74, 'end': 77}, {'entity': 'I-PER', 'score': np.float32(0.98204434), 'index': 27, 'word': '##ина', 'start': 77, 'end': 80}, {'entity': 'I-PER', 'score': np.float32(0.9996425), 'index': 28, 'word': 'Не', 'start': 81, 'end': 83}, {'entity': 'I-PER', 'score': np.float32(0.9996587), 'index': 29, 'word': '##да', 'start': 83, 'end': 85}, {'entity': 'I-PER', 'score': np.float32(0.9995888), 'index': 30, 'word': '##шко', 'start': 85, 'end': 88}]\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/17 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f1fe27e3860c4cf380107fb67d43e2f8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of Qwen2ForTokenClassification were not initialized from the model checkpoint at Qwen/Qwen2.5-32B-Instruct and are newly initialized: ['score.bias', 'score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2/2 [09:35<00:00, 287.53s/it]\n",
            "Validating: 100%|██████████| 1/1 [02:52<00:00, 172.39s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: nan | Val Loss: nan\n",
            "\n",
            "Epoch 2/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2/2 [08:55<00:00, 267.70s/it]\n",
            "Validating: 100%|██████████| 1/1 [03:03<00:00, 183.90s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: nan | Val Loss: nan\n",
            "\n",
            "Epoch 3/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2/2 [09:15<00:00, 277.65s/it]\n",
            "Validating: 100%|██████████| 1/1 [02:54<00:00, 174.30s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: nan | Val Loss: nan\n",
            "Предсказания модели Qwen (первые 20 токенов):\n",
            "Ðĳ -> B-PER\n",
            "Ð»Ð¾Ð³ -> B-PER\n",
            "Ġ/ -> B-MISC\n",
            "ĠÐĿ -> B-PER\n",
            "Ð¾Ð² -> B-PER\n",
            "Ð¾ÑģÑĤÐ¸ -> B-PER\n",
            "ĠÐĴÐ¾Ð· -> B-PER\n",
            "ÑĢÐ¾Ð¶ -> B-MISC\n",
            "Ð´ -> B-PER\n",
            "ÐµÐ½Ð¸Ðµ -> I-PER\n",
            "ĠÐ» -> B-PER\n",
            "ÑİÑĤ -> B-PER\n",
            "Ð¾Ð² -> B-PER\n",
            "Ð¾Ð» -> B-PER\n",
            "ÐºÐ¾Ð² -> B-PER\n",
            "ĠÐ¸Ð· -> B-PER\n",
            "ĠÂ« -> I-ORG\n",
            "Ðĺ -> B-MISC\n",
            "Ð³ -> B-PER\n",
            "ÑĢÑĭ -> B-MISC\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, BertTokenizerFast, BertForTokenClassification\n",
        "from transformers import pipeline\n",
        "from typing import List, Dict, Tuple\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.optim import AdamW\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "# Конфигурация\n",
        "DEVICE = torch.device(\"cpu\")\n",
        "QWEN_MODEL_NAME =  \"Qwen/Qwen2.5-32B-Instruct\"\n",
        "BERT_MODEL_NAME = \"Davlan/bert-base-multilingual-cased-ner-hrl\" # Предобученная модель для NER\n",
        "\n",
        "from bs4 import BeautifulSoup, Comment\n",
        "import requests\n",
        "\n",
        "def extract_text_from_url(url: str, timeout: int = 10) -> str:\n",
        "    \"\"\"\n",
        "    Извлекает основной текстовый контент с веб-страницы по URL.\n",
        "\n",
        "    Параметры:\n",
        "        url (str): URL веб-страницы\n",
        "        timeout (int): Таймаут запроса в секундах (по умолчанию 10)\n",
        "\n",
        "    Возвращает:\n",
        "        str: Очищенный текстовый контент страницы\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Заголовки для имитации браузера\n",
        "        headers = {\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "        }\n",
        "\n",
        "        # Запрос с таймаутом и заголовками\n",
        "        response = requests.get(url, headers=headers, timeout=timeout)\n",
        "        response.raise_for_status()  # Проверка на ошибки HTTP\n",
        "\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Удаление нежелательных элементов\n",
        "        for element in soup(['script', 'style', 'nav', 'footer', 'iframe', 'noscript', 'svg']):\n",
        "            element.decompose()\n",
        "\n",
        "        # Удаление HTML-комментариев\n",
        "        for comment in soup.find_all(string=lambda text: isinstance(text, Comment)):\n",
        "            comment.extract()\n",
        "\n",
        "        # Извлечение текста из основных содержательных тегов\n",
        "        text_elements = []\n",
        "        for tag in ['article', 'main', 'div', 'section', 'p']:\n",
        "            elements = soup.find_all(tag)\n",
        "            for element in elements:\n",
        "                # Проверка на содержание значимого текста\n",
        "                if len(element.get_text(strip=True)) > 50:  # Минимум 50 символов\n",
        "                    text_elements.append(element.get_text(separator=' ', strip=True))\n",
        "\n",
        "        # Если не нашли достаточно текста в специфичных тегах, берем весь body\n",
        "        if not text_elements or sum(len(t) for t in text_elements) < 500:\n",
        "            text_elements = [soup.get_text(separator=' ', strip=True)]\n",
        "\n",
        "        # Объединение и очистка текста\n",
        "        text = ' '.join(text_elements)\n",
        "\n",
        "        # Удаление лишних пробелов и переносов строк\n",
        "        text = ' '.join(text.split())\n",
        "\n",
        "        return text\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Ошибка при запросе к {url}: {str(e)}\")\n",
        "        return \"\"\n",
        "    except Exception as e:\n",
        "        print(f\"Неожиданная ошибка при обработке {url}: {str(e)}\")\n",
        "        return \"\"\n",
        "\n",
        "def annotate_with_bert(text: str) -> List[Dict]:\n",
        "    \"\"\"Аннотирует текст с помощью предобученной модели BERT.\"\"\"\n",
        "    tokenizer = BertTokenizerFast.from_pretrained(BERT_MODEL_NAME)\n",
        "    model = BertForTokenClassification.from_pretrained(BERT_MODEL_NAME).to(DEVICE)\n",
        "\n",
        "    nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer, device=DEVICE)\n",
        "    annotations = nlp(text)\n",
        "    return annotations\n",
        "\n",
        "def adapt_qwen_for_ner(model_name: str = QWEN_MODEL_NAME):\n",
        "    \"\"\"Загружает модель Qwen и адаптирует её для NER.\"\"\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForTokenClassification.from_pretrained(\n",
        "        model_name,\n",
        "        num_labels=9,  # Стандартное количество классов для NER (PER, ORG, LOC и т.д.)\n",
        "        id2label={0: 'O', 1: 'B-PER', 2: 'I-PER', 3: 'B-ORG', 4: 'I-ORG',\n",
        "                  5: 'B-LOC', 6: 'I-LOC', 7: 'B-MISC', 8: 'I-MISC'},\n",
        "        label2id={'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4,\n",
        "                  'B-LOC': 5, 'I-LOC': 6, 'B-MISC': 7, 'I-MISC': 8}\n",
        "    ).to(DEVICE)\n",
        "\n",
        "    # Замораживаем все слои, кроме последнего\n",
        "    for param in model.base_model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "class NERDataset(Dataset):\n",
        "    \"\"\"Кастомный Dataset для NER.\"\"\"\n",
        "    def __init__(self, texts, annotations, tokenizer, model_config, max_length=128):\n",
        "        self.texts = texts\n",
        "        self.annotations = annotations\n",
        "        self.tokenizer = tokenizer\n",
        "        self.model_config = model_config  # Добавляем конфигурацию модели\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        annotations = self.annotations[idx]\n",
        "\n",
        "        # Токенизация с выравниванием меток\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            max_length=self.max_length,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            return_tensors='pt',\n",
        "            return_offsets_mapping=True\n",
        "        )\n",
        "\n",
        "        # Создаем массив меток, заполненный -100 (игнорируется при вычислении потерь)\n",
        "        labels = torch.full((self.max_length,), -100, dtype=torch.long)\n",
        "\n",
        "        # Преобразуем аннотации в метки для токенов\n",
        "        offset_mapping = encoding['offset_mapping'][0]\n",
        "        for ann in annotations:\n",
        "            start, end = ann['start'], ann['end']\n",
        "            label = ann['entity']\n",
        "\n",
        "            # Находим токены, которые пересекаются с аннотацией\n",
        "            for i, (token_start, token_end) in enumerate(offset_mapping):\n",
        "                if token_start >= end or token_end <= start:\n",
        "                    continue\n",
        "                if token_start != 0 or token_end != 0:  # Игнорируем специальные токены\n",
        "                    labels[i] = self.model_config.label2id.get(label, 0)  # Используем self.model_config\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': labels\n",
        "        }\n",
        "\n",
        "def prepare_training_data(text, bert_annotations, tokenizer, test_size=0.2):\n",
        "    \"\"\"Подготавливает данные для обучения и валидации.\"\"\"\n",
        "    # Разделяем текст на предложения (упрощенно)\n",
        "    sentences = [sent.strip() for sent in text.split('.') if len(sent.strip()) > 0]\n",
        "\n",
        "    # Сопоставляем аннотации с предложениями (упрощенно)\n",
        "    sentence_annotations = []\n",
        "    current_pos = 0\n",
        "    for sent in sentences:\n",
        "        sent_len = len(sent)\n",
        "        sent_anns = []\n",
        "        for ann in bert_annotations:\n",
        "            if current_pos <= ann['start'] < current_pos + sent_len:\n",
        "                adjusted_ann = {\n",
        "                    'start': ann['start'] - current_pos,\n",
        "                    'end': ann['end'] - current_pos,\n",
        "                    'entity': ann['entity']\n",
        "                }\n",
        "                sent_anns.append(adjusted_ann)\n",
        "        sentence_annotations.append(sent_anns)\n",
        "        current_pos += sent_len + 1  # +1 для точки\n",
        "\n",
        "    # Разделяем на train и test\n",
        "    split_idx = int(len(sentences) * (1 - test_size))\n",
        "    train_texts, train_anns = sentences[:split_idx], sentence_annotations[:split_idx]\n",
        "    val_texts, val_anns = sentences[split_idx:], sentence_annotations[split_idx:]\n",
        "\n",
        "    return train_texts, train_anns, val_texts, val_anns\n",
        "\n",
        "def train_qwen(model, tokenizer, text, bert_annotations, epochs=3, batch_size=8, learning_rate=2e-5):\n",
        "    \"\"\"Полноценная функция обучения модели Qwen для NER.\"\"\"\n",
        "\n",
        "    # Подготовка данных\n",
        "    train_texts, train_anns, val_texts, val_anns = prepare_training_data(text, bert_annotations, tokenizer)\n",
        "\n",
        "    train_dataset = NERDataset(train_texts, train_anns, tokenizer, model_config=model.config)\n",
        "    val_dataset = NERDataset(val_texts, val_anns, tokenizer, model_config=model.config)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "    # Настройка оптимизатора и планировщика\n",
        "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "    total_steps = len(train_loader) * epochs\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=0,\n",
        "        num_training_steps=total_steps\n",
        "    )\n",
        "\n",
        "    # Обучение\n",
        "    best_val_loss = float('inf')\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "\n",
        "        # Фаза обучения\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for batch in tqdm(train_loader, desc=\"Training\"):\n",
        "            batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(\n",
        "                input_ids=batch['input_ids'],\n",
        "                attention_mask=batch['attention_mask'],\n",
        "                labels=batch['labels']\n",
        "            )\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = train_loss / len(train_loader)\n",
        "\n",
        "        # Фаза валидации\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "        for batch in tqdm(val_loader, desc=\"Validating\"):\n",
        "            batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(\n",
        "                    input_ids=batch['input_ids'],\n",
        "                    attention_mask=batch['attention_mask'],\n",
        "                    labels=batch['labels']\n",
        "                )\n",
        "\n",
        "            val_loss += outputs.loss.item()\n",
        "\n",
        "            # Собираем предсказания и метки для метрик\n",
        "            preds = torch.argmax(outputs.logits, dim=2)\n",
        "            mask = batch['labels'] != -100  # Игнорируем метки -100\n",
        "\n",
        "            all_preds.extend(preds[mask].cpu().numpy())\n",
        "            all_labels.extend(batch['labels'][mask].cpu().numpy())\n",
        "\n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "\n",
        "        # Выводим метрики\n",
        "        print(f\"Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
        "        # print(classification_report(\n",
        "        #     all_labels,\n",
        "        #     all_preds,\n",
        "        #     target_names=list(model.config.id2label.values()),\n",
        "        #     zero_division=0\n",
        "        # ))\n",
        "\n",
        "        # Сохраняем лучшую модель\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            os.makedirs(\"./qwen_ner\", exist_ok=True)\n",
        "            model.save_pretrained(\"./qwen_ner\")\n",
        "            tokenizer.save_pretrained(\"./qwen_ner\")\n",
        "            print(\"Saved best model!\")\n",
        "\n",
        "    return model\n",
        "\n",
        "def predict_with_qwen(text: str, model, tokenizer) -> List[Tuple[str, str]]:\n",
        "    \"\"\"Делает предсказания с помощью адаптированной модели Qwen.\"\"\"\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(DEVICE)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    predictions = torch.argmax(outputs.logits, dim=2)\n",
        "    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
        "    labels = [model.config.id2label[p.item()] for p in predictions[0]]\n",
        "\n",
        "    return list(zip(tokens, labels))\n",
        "\n",
        "def main(url: str):\n",
        "    # 1. Извлекаем текст с веб-страницы\n",
        "    text = extract_text_from_url(url)\n",
        "    print(f\"Извлечённый текст:\\n{text[:500]}...\\n\")\n",
        "\n",
        "    # 2. Аннотируем с помощью BERT\n",
        "    bert_annotations = annotate_with_bert(text[:512])  # Ограничиваем длину для BERT\n",
        "    print(f\"Пример аннотаций BERT:\\n{bert_annotations[:5]}\\n\")\n",
        "\n",
        "    # 3. Адаптируем Qwen для NER\n",
        "    qwen_model, qwen_tokenizer = adapt_qwen_for_ner()\n",
        "\n",
        "    # 4. Обучаем модель\n",
        "    qwen_model = train_qwen(qwen_model, qwen_tokenizer, text[:2000], bert_annotations, epochs=3)\n",
        "\n",
        "    # 5. Делаем предсказания\n",
        "    predictions = predict_with_qwen(text[:512], qwen_model, qwen_tokenizer)\n",
        "\n",
        "    # 6. Выводим результаты\n",
        "    print(\"Предсказания модели Qwen (первые 20 токенов):\")\n",
        "    for token, label in predictions[:20]:\n",
        "        print(f\"{token} -> {label}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    url = \"https://amulex.ru/daily/news/vozrozhdenie-lyutovolkov-iz-igry-prestolov-nauchnyj-proryv-bjfj4kf/?ysclid=mae5l3wify323318294\"  # Пример URL\n",
        "    main(url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9SmfpAamSL30",
      "metadata": {
        "id": "9SmfpAamSL30"
      },
      "source": [
        "# SBERBANK AI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "NzDqam4ASLci",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "f54e4d3884ba4a57bd73250829bc847c",
            "616ad4369cd44c05b153348ef75afa03",
            "9789c43ca0b240cebae1bcce30a3123a",
            "dcbac5a2a6a64ac5bba98e9e3666b004",
            "cbe2a17997ee404a86aab46125c8dfe1",
            "50742a2950bb45e1afd1093a9c0cf87c",
            "c19bd44538ed44f5a28f15816e6f5da0",
            "b4d23905912f4407b8e01b07437e5c1e",
            "287f20ab102949c0abefb38d27636e46",
            "2143b5e42f3b45be80b41300d7a3e67a",
            "5c9687d8faba40cd8b618e3e8165f5c4",
            "5f0a483742d647c69bcedd51b02aab8f",
            "e553f2385c8344478983af89e900cdfd",
            "21fe7692bd764ec7bd132b303109111f",
            "ba0260793b81403c9563435181511509",
            "a971c74f4c70483e8a625876f8766d61",
            "3236349132c449df9d9bad5bcdfd4d29",
            "1bab2ea7fa0c4d53aeb79883dcfef27a",
            "453e83b2bb6848dea06a24c1137f1974",
            "895fd79f1e21402b91ec9171fb5d5356",
            "6f9fdb6ecbe74a99ba56fb9ec2010bc2",
            "02bb8370c8844fbca9e18f9cb46f7d4f",
            "f2ee1a362f8649938176c5d574a67d0a",
            "1d66730e1e494b0da0ad8964c4ea6bf9",
            "ac1daad9f4ad4648a26b07b8fde85e62",
            "b181b4643e9640deb1e8154a12a1071c",
            "d249608531c3429686f845be72a2700d",
            "4ba5b3b09ff5479c8a938ca6f016d3d3",
            "44da238043914997b1343ca5f31fe844",
            "f58fd155914540d1bb8a708d0e731984",
            "f3a6c99acd7c4f658d1c26b6562dc2d2",
            "aa0b38f506da4155b66e7543b1630c8e",
            "c6f3e3f0501b43aab97da34166ee9e26",
            "d6184576c1f649a3bb70b22bd6c41e0d",
            "68aa0b39e9804b7094c8cef8d8340ab5",
            "f3929abeea6b49a0a01a32c40d8d6aba",
            "9cddc9daea944560aa37540e40fcb4ed",
            "2a90e034a81b438387e05b2bda303b2c",
            "ceadcf6233ad425b9bc7d788a53d1f74",
            "12762a38b8ea498e8bc46588c50dc9a8",
            "7e6f51b879e84d81b1ab87275ea1bb08",
            "0a0c9fe08f4c4e89853021a3e76fceee",
            "4cdb71be5a054dfab61a7aa579725339",
            "942619f6233248099a60469213f2f56c",
            "c1daefac5def47afb007ef0e724c028d",
            "4abe5d9474174b5b84972da1eb8e7910",
            "708b415e0e3a40fb94ec36aad5b6d6cd",
            "b045c6c6782e4627816d847e03bf6205",
            "4d38b1b204b243818479d73cc76cd8e1",
            "876085e7eb484b088d238056af7013b7",
            "5d8d1b1201df44ae8fc217e83fe121c7",
            "57e3b2afba7d48bdb4cf5b8d1a7af858",
            "80d84353f43640afb1978fe067792e47",
            "6c6bfecdef9740b7bb51703c68845761",
            "64dba4ee1a4e4457a1127652a36d4f41",
            "6eb04acf75a14c5a8fb948c3ce2eed6f",
            "ea3781060fca4022a5751af068029e8e",
            "746dd2df7cbd420da8c341cfcfd49ae1",
            "ccbe6da0e6624fc382f7e3fb6b3990d9",
            "e5043865331a4d27a442754e12d917dd",
            "52af585950744b2ba91214d53dfaddb2",
            "1dbb78b204664d1d90f34da67aa6627d",
            "a1280cecb332473f9494c68d7866c412",
            "f6853b48bca046109856fcebc6ab2037",
            "291e40a292354dbe9f1ac378e4bd96d4",
            "3978fd6387a94b829e646abd79732d49",
            "f203c48443cd462f911d08ae63000293",
            "34d222820996421680d193c5fd564d62",
            "68e5b184f2454aac9bf826241bd7ceb3",
            "1b4b2912953a4180b671edb133f9d70f",
            "c846148774804d32937b5557562fa134",
            "e5ec2aa2eb6149859b622d9db25fa55a",
            "76d00e82d86349e2ba8ff5e7782858ca",
            "ccc85ee996cb4b458dcb08bd57a65500",
            "624020d0b28a4e8287e681855092935d",
            "3a12ebf7a8d84b0e8c71d3691ebffb83",
            "82853561892b414190baee66e11c1f73",
            "7f41be0b675b431b8dc03e16f910261c",
            "c404c9b825e9484f855d6722af38d88d",
            "0e47c48fcf8440d78fc739543e56ebe8",
            "406c098bbdc840d09d6545acfec7577c",
            "243accb0267049b886fd15fa4bcfb7e1",
            "37b12e9f49f244538128ffad8c267eea",
            "4a19727cc8ec47889bcdc399ec9e7ec6",
            "0b7f2ff176b44d7abf84a70a2f18f6a7",
            "84c1f5040924462eb9240a9341078882",
            "c2ace6a6f7c64958afc689921688e1be",
            "4baa4bcf86ba44858f9bb349eed2e109"
          ]
        },
        "id": "NzDqam4ASLci",
        "outputId": "0593108b-d3b5-4b35-89b0-2058fcbd4b0c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Извлечённый текст:\n",
            "Блог / Новости Возрождение лютоволков из «Игры престолов»: научный прорыв Полина Недашковская 07 мая, 2025 • 2 мин • 157 Копировать ссылку Telegram VK WhatsApp Биотехнологическая компания Colossal Biosciences из Далласа совершила прорыв в области возрождения вымерших видов животных, воссоздав ужасных волков (dire wolves), известных широкой аудитории как «лютоволки» из «Игры престолов» . Процесс был долгим и сложным, но в итоге ученые смогли вернуть к жизни этот вид, вымерший более 12 тысяч лет н...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/264 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f54e4d3884ba4a57bd73250829bc847c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/996k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5f0a483742d647c69bcedd51b02aab8f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f2ee1a362f8649938176c5d574a67d0a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.10k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d6184576c1f649a3bb70b22bd6c41e0d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/709M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c1daefac5def47afb007ef0e724c028d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Пример аннотаций BERT:\n",
            "[{'entity': 'B-PER', 'score': np.float32(0.9995003), 'index': 26, 'word': 'Пол', 'start': 74, 'end': 77}, {'entity': 'I-PER', 'score': np.float32(0.9840973), 'index': 27, 'word': '##ина', 'start': 77, 'end': 80}, {'entity': 'I-PER', 'score': np.float32(0.9996512), 'index': 28, 'word': 'Не', 'start': 81, 'end': 83}, {'entity': 'I-PER', 'score': np.float32(0.99967647), 'index': 29, 'word': '##да', 'start': 83, 'end': 85}, {'entity': 'I-PER', 'score': np.float32(0.9995914), 'index': 30, 'word': '##шко', 'start': 85, 'end': 88}]\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/591 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6eb04acf75a14c5a8fb948c3ce2eed6f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/1.78M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f203c48443cd462f911d08ae63000293"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/1.71G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7f41be0b675b431b8dc03e16f910261c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForTokenClassification were not initialized from the model checkpoint at sberbank-ai/ruBert-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2/2 [00:14<00:00,  7.42s/it]\n",
            "Validating: 100%|██████████| 1/1 [00:04<00:00,  4.70s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: nan | Val Loss: nan\n",
            "\n",
            "Epoch 2/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2/2 [00:15<00:00,  7.85s/it]\n",
            "Validating: 100%|██████████| 1/1 [00:04<00:00,  4.70s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: nan | Val Loss: nan\n",
            "\n",
            "Epoch 3/3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training: 100%|██████████| 2/2 [00:14<00:00,  7.20s/it]\n",
            "Validating: 100%|██████████| 1/1 [00:04<00:00,  4.80s/it]\n",
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss: nan | Val Loss: nan\n",
            "Предсказания модели Qwen (первые 20 токенов):\n",
            "[CLS] -> B-PER\n",
            "блог -> B-ORG\n",
            "/ -> B-ORG\n",
            "новости -> I-LOC\n",
            "возрождение -> B-PER\n",
            "люто -> I-ORG\n",
            "##вол -> I-ORG\n",
            "##ков -> I-MISC\n",
            "из -> I-ORG\n",
            "« -> B-ORG\n",
            "игры -> B-ORG\n",
            "престолов -> B-ORG\n",
            "» -> B-MISC\n",
            ": -> B-ORG\n",
            "науч -> I-ORG\n",
            "##ны -> B-MISC\n",
            "##и -> B-ORG\n",
            "прорыв -> B-PER\n",
            "поли -> I-MISC\n",
            "##на -> I-PER\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification, BertTokenizerFast, BertForTokenClassification\n",
        "from transformers import pipeline\n",
        "from typing import List, Dict, Tuple\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.optim import AdamW\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "# Конфигурация\n",
        "DEVICE = torch.device(\"cpu\")\n",
        "QWEN_MODEL_NAME =  \"sberbank-ai/ruBert-large\"\n",
        "BERT_MODEL_NAME = \"Davlan/bert-base-multilingual-cased-ner-hrl\"  # Предобученная BERT для NER\n",
        "\n",
        "from bs4 import BeautifulSoup, Comment\n",
        "import requests\n",
        "\n",
        "from bs4 import BeautifulSoup, Comment\n",
        "import requests\n",
        "\n",
        "def extract_text_from_url(url: str, timeout: int = 10) -> str:\n",
        "    \"\"\"\n",
        "    Извлекает основной текстовый контент с веб-страницы по URL.\n",
        "\n",
        "    Параметры:\n",
        "        url (str): URL веб-страницы\n",
        "        timeout (int): Таймаут запроса в секундах (по умолчанию 10)\n",
        "\n",
        "    Возвращает:\n",
        "        str: Очищенный текстовый контент страницы\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Заголовки для имитации браузера\n",
        "        headers = {\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "        }\n",
        "\n",
        "        # Запрос с таймаутом и заголовками\n",
        "        response = requests.get(url, headers=headers, timeout=timeout)\n",
        "        response.raise_for_status()  # Проверка на ошибки HTTP\n",
        "\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Удаление нежелательных элементов\n",
        "        for element in soup(['script', 'style', 'nav', 'footer', 'iframe', 'noscript', 'svg']):\n",
        "            element.decompose()\n",
        "\n",
        "        # Удаление HTML-комментариев\n",
        "        for comment in soup.find_all(string=lambda text: isinstance(text, Comment)):\n",
        "            comment.extract()\n",
        "\n",
        "        # Извлечение текста из основных содержательных тегов\n",
        "        text_elements = []\n",
        "        for tag in ['article', 'main', 'div', 'section', 'p']:\n",
        "            elements = soup.find_all(tag)\n",
        "            for element in elements:\n",
        "                # Проверка на содержание значимого текста\n",
        "                if len(element.get_text(strip=True)) > 50:  # Минимум 50 символов\n",
        "                    text_elements.append(element.get_text(separator=' ', strip=True))\n",
        "\n",
        "        # Если не нашли достаточно текста в специфичных тегах, берем весь body\n",
        "        if not text_elements or sum(len(t) for t in text_elements) < 500:\n",
        "            text_elements = [soup.get_text(separator=' ', strip=True)]\n",
        "\n",
        "        # Объединение и очистка текста\n",
        "        text = ' '.join(text_elements)\n",
        "\n",
        "        # Удаление лишних пробелов и переносов строк\n",
        "        text = ' '.join(text.split())\n",
        "\n",
        "        return text\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Ошибка при запросе к {url}: {str(e)}\")\n",
        "        return \"\"\n",
        "    except Exception as e:\n",
        "        print(f\"Неожиданная ошибка при обработке {url}: {str(e)}\")\n",
        "        return \"\"\n",
        "\n",
        "def annotate_with_bert(text: str) -> List[Dict]:\n",
        "    \"\"\"Аннотирует текст с помощью предобученной модели BERT.\"\"\"\n",
        "    tokenizer = BertTokenizerFast.from_pretrained(BERT_MODEL_NAME)\n",
        "    model = BertForTokenClassification.from_pretrained(BERT_MODEL_NAME).to(DEVICE)\n",
        "\n",
        "    nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer, device=DEVICE)\n",
        "    annotations = nlp(text)\n",
        "    return annotations\n",
        "\n",
        "def adapt_qwen_for_ner(model_name: str = QWEN_MODEL_NAME):\n",
        "    \"\"\"Загружает модель Qwen и адаптирует её для NER.\"\"\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForTokenClassification.from_pretrained(\n",
        "        model_name,\n",
        "        num_labels=9,  # Стандартное количество классов для NER (PER, ORG, LOC и т.д.)\n",
        "        id2label={0: 'O', 1: 'B-PER', 2: 'I-PER', 3: 'B-ORG', 4: 'I-ORG',\n",
        "                  5: 'B-LOC', 6: 'I-LOC', 7: 'B-MISC', 8: 'I-MISC'},\n",
        "        label2id={'O': 0, 'B-PER': 1, 'I-PER': 2, 'B-ORG': 3, 'I-ORG': 4,\n",
        "                  'B-LOC': 5, 'I-LOC': 6, 'B-MISC': 7, 'I-MISC': 8}\n",
        "    ).to(DEVICE)\n",
        "\n",
        "    # Замораживаем все слои, кроме последнего\n",
        "    for param in model.base_model.parameters():\n",
        "        param.requires_grad = False\n",
        "\n",
        "    return model, tokenizer\n",
        "\n",
        "class NERDataset(Dataset):\n",
        "    \"\"\"Кастомный Dataset для NER.\"\"\"\n",
        "    def __init__(self, texts, annotations, tokenizer, model_config, max_length=128):\n",
        "        self.texts = texts\n",
        "        self.annotations = annotations\n",
        "        self.tokenizer = tokenizer\n",
        "        self.model_config = model_config  # Добавляем конфигурацию модели\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        annotations = self.annotations[idx]\n",
        "\n",
        "        # Токенизация с выравниванием меток\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            max_length=self.max_length,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            return_tensors='pt',\n",
        "            return_offsets_mapping=True\n",
        "        )\n",
        "\n",
        "        # Создаем массив меток, заполненный -100 (игнорируется при вычислении потерь)\n",
        "        labels = torch.full((self.max_length,), -100, dtype=torch.long)\n",
        "\n",
        "        # Преобразуем аннотации в метки для токенов\n",
        "        offset_mapping = encoding['offset_mapping'][0]\n",
        "        for ann in annotations:\n",
        "            start, end = ann['start'], ann['end']\n",
        "            label = ann['entity']\n",
        "\n",
        "            # Находим токены, которые пересекаются с аннотацией\n",
        "            for i, (token_start, token_end) in enumerate(offset_mapping):\n",
        "                if token_start >= end or token_end <= start:\n",
        "                    continue\n",
        "                if token_start != 0 or token_end != 0:  # Игнорируем специальные токены\n",
        "                    labels[i] = self.model_config.label2id.get(label, 0)  # Используем self.model_config\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': labels\n",
        "        }\n",
        "\n",
        "def prepare_training_data(text, bert_annotations, tokenizer, test_size=0.2):\n",
        "    \"\"\"Подготавливает данные для обучения и валидации.\"\"\"\n",
        "    # Разделяем текст на предложения (упрощенно)\n",
        "    sentences = [sent.strip() for sent in text.split('.') if len(sent.strip()) > 0]\n",
        "\n",
        "    # Сопоставляем аннотации с предложениями (упрощенно)\n",
        "    sentence_annotations = []\n",
        "    current_pos = 0\n",
        "    for sent in sentences:\n",
        "        sent_len = len(sent)\n",
        "        sent_anns = []\n",
        "        for ann in bert_annotations:\n",
        "            if current_pos <= ann['start'] < current_pos + sent_len:\n",
        "                adjusted_ann = {\n",
        "                    'start': ann['start'] - current_pos,\n",
        "                    'end': ann['end'] - current_pos,\n",
        "                    'entity': ann['entity']\n",
        "                }\n",
        "                sent_anns.append(adjusted_ann)\n",
        "        sentence_annotations.append(sent_anns)\n",
        "        current_pos += sent_len + 1  # +1 для точки\n",
        "\n",
        "    # Разделяем на train и test\n",
        "    split_idx = int(len(sentences) * (1 - test_size))\n",
        "    train_texts, train_anns = sentences[:split_idx], sentence_annotations[:split_idx]\n",
        "    val_texts, val_anns = sentences[split_idx:], sentence_annotations[split_idx:]\n",
        "\n",
        "    return train_texts, train_anns, val_texts, val_anns\n",
        "\n",
        "def train_qwen(model, tokenizer, text, bert_annotations, epochs=3, batch_size=8, learning_rate=2e-5):\n",
        "    \"\"\"Полноценная функция обучения модели Qwen для NER.\"\"\"\n",
        "\n",
        "    # Подготовка данных\n",
        "    train_texts, train_anns, val_texts, val_anns = prepare_training_data(text, bert_annotations, tokenizer)\n",
        "\n",
        "    train_dataset = NERDataset(train_texts, train_anns, tokenizer, model_config=model.config)\n",
        "    val_dataset = NERDataset(val_texts, val_anns, tokenizer, model_config=model.config)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "    # Настройка оптимизатора и планировщика\n",
        "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "    total_steps = len(train_loader) * epochs\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=0,\n",
        "        num_training_steps=total_steps\n",
        "    )\n",
        "\n",
        "    # Обучение\n",
        "    best_val_loss = float('inf')\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "\n",
        "        # Фаза обучения\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for batch in tqdm(train_loader, desc=\"Training\"):\n",
        "            batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(\n",
        "                input_ids=batch['input_ids'],\n",
        "                attention_mask=batch['attention_mask'],\n",
        "                labels=batch['labels']\n",
        "            )\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = train_loss / len(train_loader)\n",
        "\n",
        "        # Фаза валидации\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "        for batch in tqdm(val_loader, desc=\"Validating\"):\n",
        "            batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(\n",
        "                    input_ids=batch['input_ids'],\n",
        "                    attention_mask=batch['attention_mask'],\n",
        "                    labels=batch['labels']\n",
        "                )\n",
        "\n",
        "            val_loss += outputs.loss.item()\n",
        "\n",
        "            # Собираем предсказания и метки для метрик\n",
        "            preds = torch.argmax(outputs.logits, dim=2)\n",
        "            mask = batch['labels'] != -100  # Игнорируем метки -100\n",
        "\n",
        "            all_preds.extend(preds[mask].cpu().numpy())\n",
        "            all_labels.extend(batch['labels'][mask].cpu().numpy())\n",
        "\n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "\n",
        "        # Выводим метрики\n",
        "        print(f\"Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
        "        # print(classification_report(\n",
        "        #     all_labels,\n",
        "        #     all_preds,\n",
        "        #     target_names=list(model.config.id2label.values()),\n",
        "        #     zero_division=0\n",
        "        # ))\n",
        "\n",
        "        # Сохраняем лучшую модель\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            os.makedirs(\"./qwen_ner\", exist_ok=True)\n",
        "            model.save_pretrained(\"./qwen_ner\")\n",
        "            tokenizer.save_pretrained(\"./qwen_ner\")\n",
        "            print(\"Saved best model!\")\n",
        "\n",
        "    return model\n",
        "\n",
        "def predict_with_qwen(text: str, model, tokenizer) -> List[Tuple[str, str]]:\n",
        "    \"\"\"Делает предсказания с помощью адаптированной модели Qwen.\"\"\"\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(DEVICE)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    predictions = torch.argmax(outputs.logits, dim=2)\n",
        "    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
        "    labels = [model.config.id2label[p.item()] for p in predictions[0]]\n",
        "\n",
        "    return list(zip(tokens, labels))\n",
        "\n",
        "def main(url: str):\n",
        "    # 1. Извлекаем текст с веб-страницы\n",
        "    text = extract_text_from_url(url)\n",
        "    print(f\"Извлечённый текст:\\n{text[:500]}...\\n\")\n",
        "\n",
        "    # 2. Аннотируем с помощью BERT\n",
        "    bert_annotations = annotate_with_bert(text[:512])  # Ограничиваем длину для BERT\n",
        "    print(f\"Пример аннотаций BERT:\\n{bert_annotations[:5]}\\n\")\n",
        "\n",
        "    # 3. Адаптируем Qwen для NER\n",
        "    qwen_model, qwen_tokenizer = adapt_qwen_for_ner()\n",
        "\n",
        "    # 4. Обучаем модель\n",
        "    qwen_model = train_qwen(qwen_model, qwen_tokenizer, text[:2000], bert_annotations, epochs=3)\n",
        "\n",
        "    # 5. Делаем предсказания\n",
        "    predictions = predict_with_qwen(text[:512], qwen_model, qwen_tokenizer)\n",
        "\n",
        "    # 6. Выводим результаты\n",
        "    print(\"Предсказания модели Qwen (первые 20 токенов):\")\n",
        "    for token, label in predictions[:20]:\n",
        "        print(f\"{token} -> {label}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    url = \"https://amulex.ru/daily/news/vozrozhdenie-lyutovolkov-iz-igry-prestolov-nauchnyj-proryv-bjfj4kf/?ysclid=mae5l3wify323318294\"  # Пример URL\n",
        "    main(url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TTg16OfpKd-c",
      "metadata": {
        "id": "TTg16OfpKd-c"
      },
      "source": [
        "# FACEBOOK AI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "KMp-0M8qKezD",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KMp-0M8qKezD",
        "outputId": "71b790d5-5f50-4618-a024-d5336aebe6a9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Извлечённый текст:\n",
            "Блог / Новости Возрождение лютоволков из «Игры престолов»: научный прорыв Полина Недашковская 07 мая, 2025 • 2 мин • 144 Копировать ссылку Telegram VK WhatsApp Биотехнологическая компания Colossal Biosciences из Далласа совершила прорыв в области возрождения вымерших видов животных, воссоздав ужасных волков (dire wolves), известных широкой аудитории как «лютоволки» из «Игры престолов» . Процесс был долгим и сложным, но в итоге ученые смогли вернуть к жизни этот вид, вымерший более 12 тысяч лет н...\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at FacebookAI/xlm-roberta-large-finetuned-conll03-english were not used when initializing XLMRobertaForTokenClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Пример аннотаций XLM-RoBERTa:\n",
            "[{'entity': 'I-MISC', 'score': np.float32(0.9999461), 'index': 4, 'word': 'И', 'start': 42, 'end': 43}, {'entity': 'I-MISC', 'score': np.float32(0.9999021), 'index': 4, 'word': 'г', 'start': 43, 'end': 44}, {'entity': 'I-MISC', 'score': np.float32(0.99977), 'index': 4, 'word': 'ры', 'start': 44, 'end': 46}, {'entity': 'I-MISC', 'score': np.float32(0.99995315), 'index': 4, 'word': '▁престол', 'start': 47, 'end': 54}, {'entity': 'I-MISC', 'score': np.float32(0.99939775), 'index': 4, 'word': 'ов', 'start': 54, 'end': 56}]\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at FacebookAI/xlm-roberta-large-finetuned-conll03-english were not used when initializing XLMRobertaForTokenClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "- This IS expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2/2 [01:45<00:00, 52.74s/it]\n",
            "Validating: 100%|██████████| 1/1 [00:04<00:00,  4.50s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: nan | Val Loss: nan\n",
            "\n",
            "Epoch 2/3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2/2 [00:49<00:00, 24.75s/it]\n",
            "Validating: 100%|██████████| 1/1 [00:04<00:00,  4.99s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: nan | Val Loss: nan\n",
            "\n",
            "Epoch 3/3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2/2 [00:51<00:00, 25.55s/it]\n",
            "Validating: 100%|██████████| 1/1 [00:05<00:00,  5.29s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: nan | Val Loss: nan\n",
            "Предсказания модели XLM-RoBERTa (первые 20 токенов):\n",
            "<s> -> O\n",
            "▁Блог -> O\n",
            "▁/ -> O\n",
            "▁Новости -> O\n",
            "▁Воз -> O\n",
            "рожден -> O\n",
            "ие -> O\n",
            "▁лют -> O\n",
            "о -> O\n",
            "вол -> O\n",
            "ков -> O\n",
            "▁из -> O\n",
            "▁« -> O\n",
            "И -> I-MISC\n",
            "г -> I-MISC\n",
            "ры -> I-MISC\n",
            "▁престол -> I-MISC\n",
            "ов -> I-MISC\n",
            "»: -> O\n",
            "▁на -> O\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "from transformers import pipeline\n",
        "from typing import List, Dict, Tuple\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.optim import AdamW\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "# Конфигурация\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "MODEL_NAME = \"FacebookAI/xlm-roberta-large-finetuned-conll03-english\"\n",
        "\n",
        "from bs4 import BeautifulSoup, Comment\n",
        "import requests\n",
        "\n",
        "def extract_text_from_url(url: str, timeout: int = 10) -> str:\n",
        "    \"\"\"\n",
        "    Извлекает основной текстовый контент с веб-страницы по URL.\n",
        "\n",
        "    Параметры:\n",
        "        url (str): URL веб-страницы\n",
        "        timeout (int): Таймаут запроса в секундах (по умолчанию 10)\n",
        "\n",
        "    Возвращает:\n",
        "        str: Очищенный текстовый контент страницы\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Заголовки для имитации браузера\n",
        "        headers = {\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "        }\n",
        "\n",
        "        # Запрос с таймаутом и заголовками\n",
        "        response = requests.get(url, headers=headers, timeout=timeout)\n",
        "        response.raise_for_status()  # Проверка на ошибки HTTP\n",
        "\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Удаление нежелательных элементов\n",
        "        for element in soup(['script', 'style', 'nav', 'footer', 'iframe', 'noscript', 'svg']):\n",
        "            element.decompose()\n",
        "\n",
        "        # Удаление HTML-комментариев\n",
        "        for comment in soup.find_all(string=lambda text: isinstance(text, Comment)):\n",
        "            comment.extract()\n",
        "\n",
        "        # Извлечение текста из основных содержательных тегов\n",
        "        text_elements = []\n",
        "        for tag in ['article', 'main', 'div', 'section', 'p']:\n",
        "            elements = soup.find_all(tag)\n",
        "            for element in elements:\n",
        "                # Проверка на содержание значимого текста\n",
        "                if len(element.get_text(strip=True)) > 50:  # Минимум 50 символов\n",
        "                    text_elements.append(element.get_text(separator=' ', strip=True))\n",
        "\n",
        "        # Если не нашли достаточно текста в специфичных тегах, берем весь body\n",
        "        if not text_elements or sum(len(t) for t in text_elements) < 500:\n",
        "            text_elements = [soup.get_text(separator=' ', strip=True)]\n",
        "\n",
        "        # Объединение и очистка текста\n",
        "        text = ' '.join(text_elements)\n",
        "\n",
        "        # Удаление лишних пробелов и переносов строк\n",
        "        text = ' '.join(text.split())\n",
        "\n",
        "        return text\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Ошибка при запросе к {url}: {str(e)}\")\n",
        "        return \"\"\n",
        "    except Exception as e:\n",
        "        print(f\"Неожиданная ошибка при обработке {url}: {str(e)}\")\n",
        "        return \"\"\n",
        "\n",
        "def annotate_with_xlm_roberta(text: str) -> List[Dict]:\n",
        "    \"\"\"Аннотирует текст с помощью предобученной модели XLM-RoBERTa.\"\"\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "    model = AutoModelForTokenClassification.from_pretrained(MODEL_NAME).to(DEVICE)\n",
        "\n",
        "    nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer, device=0 if DEVICE.type == \"cuda\" else -1)\n",
        "    annotations = nlp(text)\n",
        "\n",
        "    # Добавляем индекс сущности в соответствии с id2label модели\n",
        "    label2id = model.config.label2id\n",
        "    for ann in annotations:\n",
        "        ann['index'] = label2id[ann['entity']]\n",
        "\n",
        "    return annotations\n",
        "\n",
        "class NERDataset(Dataset):\n",
        "    \"\"\"Кастомный Dataset для NER.\"\"\"\n",
        "    def __init__(self, texts, annotations, tokenizer, max_length=128):\n",
        "        self.texts = texts\n",
        "        self.annotations = annotations\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "        self.label_map = {\n",
        "            'O': 0,\n",
        "            'B-PER': 1,\n",
        "            'I-PER': 2,\n",
        "            'B-ORG': 3,\n",
        "            'I-ORG': 4,\n",
        "            'B-LOC': 5,\n",
        "            'I-LOC': 6,\n",
        "            'B-MISC': 7,\n",
        "            'I-MISC': 8\n",
        "        }\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        annotations = self.annotations[idx]\n",
        "\n",
        "        # Токенизация с выравниванием меток\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            max_length=self.max_length,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            return_tensors='pt',\n",
        "            return_offsets_mapping=True\n",
        "        )\n",
        "\n",
        "        # Создаем массив меток, заполненный -100 (игнорируется при вычислении потерь)\n",
        "        labels = torch.full((self.max_length,), -100, dtype=torch.long)\n",
        "\n",
        "        # Преобразуем аннотации в метки для токенов\n",
        "        offset_mapping = encoding['offset_mapping'][0]\n",
        "        for ann in annotations:\n",
        "            start, end = ann['start'], ann['end']\n",
        "            label_idx = ann['index']  # Используем предварительно сохраненный индекс\n",
        "\n",
        "            # Находим токены, которые пересекаются с аннотацией\n",
        "            for i, (token_start, token_end) in enumerate(offset_mapping):\n",
        "                if token_start >= end or token_end <= start:\n",
        "                    continue\n",
        "                if token_start != 0 or token_end != 0:  # Игнорируем специальные токены\n",
        "                    # Убедимся, что индекс метки в допустимых пределах\n",
        "                    if 0 <= label_idx < len(self.label_map):\n",
        "                        labels[i] = label_idx\n",
        "                    else:\n",
        "                        labels[i] = 0  # По умолчанию 'O'\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': labels\n",
        "        }\n",
        "\n",
        "def prepare_training_data(text, annotations, tokenizer, test_size=0.2):\n",
        "    \"\"\"Подготавливает данные для обучения и валидации.\"\"\"\n",
        "    # Разделяем текст на предложения (упрощенно)\n",
        "    sentences = [sent.strip() for sent in text.split('.') if len(sent.strip()) > 0]\n",
        "\n",
        "    # Сопоставляем аннотации с предложениями (упрощенно)\n",
        "    sentence_annotations = []\n",
        "    current_pos = 0\n",
        "    for sent in sentences:\n",
        "        sent_len = len(sent)\n",
        "        sent_anns = []\n",
        "        for ann in annotations:\n",
        "            if current_pos <= ann['start'] < current_pos + sent_len:\n",
        "                adjusted_ann = {\n",
        "                    'start': ann['start'] - current_pos,\n",
        "                    'end': ann['end'] - current_pos,\n",
        "                    'entity': ann['entity'],\n",
        "                    'index': ann['index']  # Сохраняем индекс сущности\n",
        "                }\n",
        "                sent_anns.append(adjusted_ann)\n",
        "        sentence_annotations.append(sent_anns)\n",
        "        current_pos += sent_len + 1  # +1 для точки\n",
        "\n",
        "    # Разделяем на train и test\n",
        "    split_idx = int(len(sentences) * (1 - test_size))\n",
        "    train_texts, train_anns = sentences[:split_idx], sentence_annotations[:split_idx]\n",
        "    val_texts, val_anns = sentences[split_idx:], sentence_annotations[split_idx:]\n",
        "\n",
        "    return train_texts, train_anns, val_texts, val_anns\n",
        "\n",
        "def train_model(model, tokenizer, text, annotations, epochs=3, batch_size=8, learning_rate=2e-5):\n",
        "    \"\"\"Функция обучения модели XLM-RoBERTa для NER.\"\"\"\n",
        "\n",
        "    # Подготовка данных\n",
        "    train_texts, train_anns, val_texts, val_anns = prepare_training_data(text, annotations, tokenizer)\n",
        "\n",
        "    train_dataset = NERDataset(train_texts, train_anns, tokenizer)\n",
        "    val_dataset = NERDataset(val_texts, val_anns, tokenizer)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "    # Настройка оптимизатора и планировщика\n",
        "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "    total_steps = len(train_loader) * epochs\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=0,\n",
        "        num_training_steps=total_steps\n",
        "    )\n",
        "\n",
        "    # Обучение\n",
        "    best_val_loss = float('inf')\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "\n",
        "        # Фаза обучения\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for batch in tqdm(train_loader, desc=\"Training\"):\n",
        "            batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(\n",
        "                input_ids=batch['input_ids'],\n",
        "                attention_mask=batch['attention_mask'],\n",
        "                labels=batch['labels']\n",
        "            )\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = train_loss / len(train_loader)\n",
        "\n",
        "        # Фаза валидации\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "        for batch in tqdm(val_loader, desc=\"Validating\"):\n",
        "            batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(\n",
        "                    input_ids=batch['input_ids'],\n",
        "                    attention_mask=batch['attention_mask'],\n",
        "                    labels=batch['labels']\n",
        "                )\n",
        "\n",
        "            val_loss += outputs.loss.item()\n",
        "\n",
        "            # Собираем предсказания и метки для метрик\n",
        "            preds = torch.argmax(outputs.logits, dim=2)\n",
        "            mask = batch['labels'] != -100  # Игнорируем метки -100\n",
        "\n",
        "            all_preds.extend(preds[mask].cpu().numpy())\n",
        "            all_labels.extend(batch['labels'][mask].cpu().numpy())\n",
        "\n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "\n",
        "        # Выводим метрики\n",
        "        print(f\"Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
        "        # print(classification_report(\n",
        "        #     all_labels,\n",
        "        #     all_preds,\n",
        "        #     target_names=list(model.config.id2label.values()),\n",
        "        #     zero_division=0\n",
        "        # ))\n",
        "\n",
        "        # Сохраняем лучшую модель\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            os.makedirs(\"./xlm_roberta_ner\", exist_ok=True)\n",
        "            model.save_pretrained(\"./xlm_roberta_ner\")\n",
        "            tokenizer.save_pretrained(\"./xlm_roberta_ner\")\n",
        "            print(\"Saved best model!\")\n",
        "\n",
        "    return model\n",
        "\n",
        "def predict_with_model(text: str, model, tokenizer) -> List[Tuple[str, str]]:\n",
        "    \"\"\"Делает предсказания с помощью модели XLM-RoBERTa.\"\"\"\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(DEVICE)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    predictions = torch.argmax(outputs.logits, dim=2)\n",
        "    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
        "    labels = [model.config.id2label[p.item()] for p in predictions[0]]\n",
        "\n",
        "    return list(zip(tokens, labels))\n",
        "\n",
        "def main(url: str):\n",
        "    # 1. Извлекаем текст с веб-страницы\n",
        "    text = extract_text_from_url(url)\n",
        "    print(f\"Извлечённый текст:\\n{text[:500]}...\\n\")\n",
        "\n",
        "    # 2. Аннотируем с помощью XLM-RoBERTa\n",
        "    annotations = annotate_with_xlm_roberta(text[:512])  # Ограничиваем длину для модели\n",
        "    print(f\"Пример аннотаций XLM-RoBERTa:\\n{annotations[:5]}\\n\")\n",
        "\n",
        "    # 3. Загружаем модель и токенизатор\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "    model = AutoModelForTokenClassification.from_pretrained(MODEL_NAME).to(DEVICE)\n",
        "\n",
        "    # 4. Обучаем модель (дообучение)\n",
        "    model = train_model(model, tokenizer, text[:2000], annotations, epochs=3)\n",
        "\n",
        "    # 5. Делаем предсказания\n",
        "    predictions = predict_with_model(text[:512], model, tokenizer)\n",
        "\n",
        "    # 6. Выводим результаты\n",
        "    print(\"Предсказания модели XLM-RoBERTa (первые 20 токенов):\")\n",
        "    for token, label in predictions[:20]:\n",
        "        print(f\"{token} -> {label}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    url = \"https://amulex.ru/daily/news/vozrozhdenie-lyutovolkov-iz-igry-prestolov-nauchnyj-proryv-bjfj4kf/?ysclid=mae5l3wify323318294\"\n",
        "    main(url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "P5RUEEzrPVw7",
      "metadata": {
        "id": "P5RUEEzrPVw7"
      },
      "source": [
        "# Babelscape/wikineural-multilingual-ner\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "lfIBee0kPWML",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfIBee0kPWML",
        "outputId": "84ee4fa1-a580-4fb8-e294-0570e6ade379"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Извлечённый текст:\n",
            "Блог / Новости Возрождение лютоволков из «Игры престолов»: научный прорыв Полина Недашковская 07 мая, 2025 • 2 мин • 150 Копировать ссылку Telegram VK WhatsApp Биотехнологическая компания Colossal Biosciences из Далласа совершила прорыв в области возрождения вымерших видов животных, воссоздав ужасных волков (dire wolves), известных широкой аудитории как «лютоволки» из «Игры престолов» . Процесс был долгим и сложным, но в итоге ученые смогли вернуть к жизни этот вид, вымерший более 12 тысяч лет н...\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Пример аннотаций WikiNeural:\n",
            "[{'entity': 'I-MISC', 'score': np.float32(0.57293886), 'index': 8, 'word': '##гр', 'start': 43, 'end': 45}, {'entity': 'I-MISC', 'score': np.float32(0.59628475), 'index': 8, 'word': '##ы', 'start': 45, 'end': 46}, {'entity': 'I-MISC', 'score': np.float32(0.5956247), 'index': 8, 'word': 'престол', 'start': 47, 'end': 54}, {'entity': 'I-MISC', 'score': np.float32(0.5244818), 'index': 8, 'word': '##ов', 'start': 54, 'end': 56}, {'entity': 'B-PER', 'score': np.float32(0.99309933), 'index': 1, 'word': 'Пол', 'start': 74, 'end': 77}]\n",
            "\n",
            "\n",
            "Epoch 1/3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2/2 [00:40<00:00, 20.09s/it]\n",
            "Validating: 100%|██████████| 1/1 [00:01<00:00,  1.80s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: nan | Val Loss: nan\n",
            "\n",
            "Epoch 2/3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2/2 [00:17<00:00,  8.70s/it]\n",
            "Validating: 100%|██████████| 1/1 [00:01<00:00,  1.40s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: nan | Val Loss: nan\n",
            "\n",
            "Epoch 3/3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training: 100%|██████████| 2/2 [00:16<00:00,  8.15s/it]\n",
            "Validating: 100%|██████████| 1/1 [00:01<00:00,  1.70s/it]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss: nan | Val Loss: nan\n",
            "Предсказания модели WikiNeural (первые 20 токенов):\n",
            "[CLS] -> O\n",
            "Б -> I-MISC\n",
            "##лог -> I-MISC\n",
            "/ -> O\n",
            "Ново -> I-MISC\n",
            "##сти -> I-MISC\n",
            "Во -> I-MISC\n",
            "##з -> O\n",
            "##ро -> O\n",
            "##ждение -> I-MISC\n",
            "л -> O\n",
            "##ют -> O\n",
            "##ово -> O\n",
            "##лков -> O\n",
            "из -> O\n",
            "« -> I-MISC\n",
            "И -> I-MISC\n",
            "##гр -> I-MISC\n",
            "##ы -> I-MISC\n",
            "престол -> I-MISC\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "from transformers import pipeline\n",
        "from typing import List, Dict, Tuple\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.optim import AdamW\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "\n",
        "# Конфигурация\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "MODEL_NAME = \"Babelscape/wikineural-multilingual-ner\"\n",
        "\n",
        "from bs4 import BeautifulSoup, Comment\n",
        "import requests\n",
        "\n",
        "def extract_text_from_url(url: str, timeout: int = 10) -> str:\n",
        "    \"\"\"\n",
        "    Извлекает основной текстовый контент с веб-страницы по URL.\n",
        "\n",
        "    Параметры:\n",
        "        url (str): URL веб-страницы\n",
        "        timeout (int): Таймаут запроса в секундах (по умолчанию 10)\n",
        "\n",
        "    Возвращает:\n",
        "        str: Очищенный текстовый контент страницы\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Заголовки для имитации браузера\n",
        "        headers = {\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "        }\n",
        "\n",
        "        # Запрос с таймаутом и заголовками\n",
        "        response = requests.get(url, headers=headers, timeout=timeout)\n",
        "        response.raise_for_status()  # Проверка на ошибки HTTP\n",
        "\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Удаление нежелательных элементов\n",
        "        for element in soup(['script', 'style', 'nav', 'footer', 'iframe', 'noscript', 'svg']):\n",
        "            element.decompose()\n",
        "\n",
        "        # Удаление HTML-комментариев\n",
        "        for comment in soup.find_all(string=lambda text: isinstance(text, Comment)):\n",
        "            comment.extract()\n",
        "\n",
        "        # Извлечение текста из основных содержательных тегов\n",
        "        text_elements = []\n",
        "        for tag in ['article', 'main', 'div', 'section', 'p']:\n",
        "            elements = soup.find_all(tag)\n",
        "            for element in elements:\n",
        "                # Проверка на содержание значимого текста\n",
        "                if len(element.get_text(strip=True)) > 50:  # Минимум 50 символов\n",
        "                    text_elements.append(element.get_text(separator=' ', strip=True))\n",
        "\n",
        "        # Если не нашли достаточно текста в специфичных тегах, берем весь body\n",
        "        if not text_elements or sum(len(t) for t in text_elements) < 500:\n",
        "            text_elements = [soup.get_text(separator=' ', strip=True)]\n",
        "\n",
        "        # Объединение и очистка текста\n",
        "        text = ' '.join(text_elements)\n",
        "\n",
        "        # Удаление лишних пробелов и переносов строк\n",
        "        text = ' '.join(text.split())\n",
        "\n",
        "        return text\n",
        "\n",
        "    except requests.exceptions.RequestException as e:\n",
        "        print(f\"Ошибка при запросе к {url}: {str(e)}\")\n",
        "        return \"\"\n",
        "    except Exception as e:\n",
        "        print(f\"Неожиданная ошибка при обработке {url}: {str(e)}\")\n",
        "        return \"\"\n",
        "\n",
        "def annotate_with_wikineural(text: str) -> List[Dict]:\n",
        "    \"\"\"Аннотирует текст с помощью модели WikiNeural.\"\"\"\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "    model = AutoModelForTokenClassification.from_pretrained(MODEL_NAME).to(DEVICE)\n",
        "\n",
        "    nlp = pipeline(\"ner\", model=model, tokenizer=tokenizer, device=0 if DEVICE.type == \"cuda\" else -1)\n",
        "    annotations = nlp(text)\n",
        "\n",
        "    # Добавляем индекс сущности в соответствии с id2label модели\n",
        "    label2id = model.config.label2id\n",
        "    for ann in annotations:\n",
        "        ann['index'] = label2id[ann['entity']]\n",
        "\n",
        "    return annotations\n",
        "\n",
        "class NERDataset(Dataset):\n",
        "    \"\"\"Кастомный Dataset для NER.\"\"\"\n",
        "    def __init__(self, texts, annotations, tokenizer, max_length=128):\n",
        "        self.texts = texts\n",
        "        self.annotations = annotations\n",
        "        self.tokenizer = tokenizer\n",
        "        self.max_length = max_length\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts[idx]\n",
        "        annotations = self.annotations[idx]\n",
        "\n",
        "        # Токенизация с выравниванием меток\n",
        "        encoding = self.tokenizer(\n",
        "            text,\n",
        "            max_length=self.max_length,\n",
        "            truncation=True,\n",
        "            padding='max_length',\n",
        "            return_tensors='pt',\n",
        "            return_offsets_mapping=True\n",
        "        )\n",
        "\n",
        "        # Создаем массив меток, заполненный -100 (игнорируется при вычислении потерь)\n",
        "        labels = torch.full((self.max_length,), -100, dtype=torch.long)\n",
        "\n",
        "        # Преобразуем аннотации в метки для токенов\n",
        "        offset_mapping = encoding['offset_mapping'][0]\n",
        "        for ann in annotations:\n",
        "            start, end = ann['start'], ann['end']\n",
        "            label_idx = ann['index']\n",
        "\n",
        "            # Находим токены, которые пересекаются с аннотацией\n",
        "            for i, (token_start, token_end) in enumerate(offset_mapping):\n",
        "                if token_start >= end or token_end <= start:\n",
        "                    continue\n",
        "                if token_start != 0 or token_end != 0:  # Игнорируем специальные токены\n",
        "                    labels[i] = label_idx\n",
        "\n",
        "        return {\n",
        "            'input_ids': encoding['input_ids'].flatten(),\n",
        "            'attention_mask': encoding['attention_mask'].flatten(),\n",
        "            'labels': labels\n",
        "        }\n",
        "\n",
        "def prepare_training_data(text, annotations, tokenizer, test_size=0.2):\n",
        "    \"\"\"Подготавливает данные для обучения и валидации.\"\"\"\n",
        "    # Разделяем текст на предложения (упрощенно)\n",
        "    sentences = [sent.strip() for sent in text.split('.') if len(sent.strip()) > 0]\n",
        "\n",
        "    # Сопоставляем аннотации с предложениями (упрощенно)\n",
        "    sentence_annotations = []\n",
        "    current_pos = 0\n",
        "    for sent in sentences:\n",
        "        sent_len = len(sent)\n",
        "        sent_anns = []\n",
        "        for ann in annotations:\n",
        "            if current_pos <= ann['start'] < current_pos + sent_len:\n",
        "                adjusted_ann = {\n",
        "                    'start': ann['start'] - current_pos,\n",
        "                    'end': ann['end'] - current_pos,\n",
        "                    'entity': ann['entity'],\n",
        "                    'index': ann['index']\n",
        "                }\n",
        "                sent_anns.append(adjusted_ann)\n",
        "        sentence_annotations.append(sent_anns)\n",
        "        current_pos += sent_len + 1  # +1 для точки\n",
        "\n",
        "    # Разделяем на train и test\n",
        "    split_idx = int(len(sentences) * (1 - test_size))\n",
        "    train_texts, train_anns = sentences[:split_idx], sentence_annotations[:split_idx]\n",
        "    val_texts, val_anns = sentences[split_idx:], sentence_annotations[split_idx:]\n",
        "\n",
        "    return train_texts, train_anns, val_texts, val_anns\n",
        "\n",
        "def train_model(model, tokenizer, text, annotations, epochs=3, batch_size=8, learning_rate=2e-5):\n",
        "    \"\"\"Функция обучения модели WikiNeural для NER.\"\"\"\n",
        "\n",
        "    # Подготовка данных\n",
        "    train_texts, train_anns, val_texts, val_anns = prepare_training_data(text, annotations, tokenizer)\n",
        "\n",
        "    train_dataset = NERDataset(train_texts, train_anns, tokenizer)\n",
        "    val_dataset = NERDataset(val_texts, val_anns, tokenizer)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
        "\n",
        "    # Настройка оптимизатора и планировщика\n",
        "    optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
        "    total_steps = len(train_loader) * epochs\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=0,\n",
        "        num_training_steps=total_steps\n",
        "    )\n",
        "\n",
        "    # Обучение\n",
        "    best_val_loss = float('inf')\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\nEpoch {epoch + 1}/{epochs}\")\n",
        "\n",
        "        # Фаза обучения\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for batch in tqdm(train_loader, desc=\"Training\"):\n",
        "            batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(\n",
        "                input_ids=batch['input_ids'],\n",
        "                attention_mask=batch['attention_mask'],\n",
        "                labels=batch['labels']\n",
        "            )\n",
        "            loss = outputs.loss\n",
        "            loss.backward()\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "            optimizer.step()\n",
        "            scheduler.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        avg_train_loss = train_loss / len(train_loader)\n",
        "\n",
        "        # Фаза валидации\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        all_preds = []\n",
        "        all_labels = []\n",
        "        for batch in tqdm(val_loader, desc=\"Validating\"):\n",
        "            batch = {k: v.to(DEVICE) for k, v in batch.items()}\n",
        "\n",
        "            with torch.no_grad():\n",
        "                outputs = model(\n",
        "                    input_ids=batch['input_ids'],\n",
        "                    attention_mask=batch['attention_mask'],\n",
        "                    labels=batch['labels']\n",
        "                )\n",
        "\n",
        "            val_loss += outputs.loss.item()\n",
        "\n",
        "            # Собираем предсказания и метки для метрик\n",
        "            preds = torch.argmax(outputs.logits, dim=2)\n",
        "            mask = batch['labels'] != -100  # Игнорируем метки -100\n",
        "\n",
        "            all_preds.extend(preds[mask].cpu().numpy())\n",
        "            all_labels.extend(batch['labels'][mask].cpu().numpy())\n",
        "\n",
        "        avg_val_loss = val_loss / len(val_loader)\n",
        "\n",
        "        # Выводим метрики\n",
        "        print(f\"Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f}\")\n",
        "        if len(all_labels) > 0:\n",
        "            print(classification_report(\n",
        "                all_labels,\n",
        "                all_preds,\n",
        "                target_names=list(model.config.id2label.values()),\n",
        "                zero_division=0\n",
        "            ))\n",
        "\n",
        "        # Сохраняем лучшую модель\n",
        "        if avg_val_loss < best_val_loss:\n",
        "            best_val_loss = avg_val_loss\n",
        "            os.makedirs(\"./wikineural_ner\", exist_ok=True)\n",
        "            model.save_pretrained(\"./wikineural_ner\")\n",
        "            tokenizer.save_pretrained(\"./wikineural_ner\")\n",
        "            print(\"Saved best model!\")\n",
        "\n",
        "    return model\n",
        "\n",
        "def predict_with_model(text: str, model, tokenizer) -> List[Tuple[str, str]]:\n",
        "    \"\"\"Делает предсказания с помощью модели WikiNeural.\"\"\"\n",
        "    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(DEVICE)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "\n",
        "    predictions = torch.argmax(outputs.logits, dim=2)\n",
        "    tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
        "    labels = [model.config.id2label[p.item()] for p in predictions[0]]\n",
        "\n",
        "    return list(zip(tokens, labels))\n",
        "\n",
        "def main(url: str):\n",
        "    # 1. Извлекаем текст с веб-страницы\n",
        "    text = extract_text_from_url(url)\n",
        "    print(f\"Извлечённый текст:\\n{text[:500]}...\\n\")\n",
        "\n",
        "    # 2. Аннотируем с помощью WikiNeural\n",
        "    annotations = annotate_with_wikineural(text[:512])  # Ограничиваем длину для модели\n",
        "    print(f\"Пример аннотаций WikiNeural:\\n{annotations[:5]}\\n\")\n",
        "\n",
        "    # 3. Загружаем модель и токенизатор\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "    model = AutoModelForTokenClassification.from_pretrained(MODEL_NAME).to(DEVICE)\n",
        "\n",
        "    # 4. Обучаем модель (дообучение)\n",
        "    model = train_model(model, tokenizer, text[:2000], annotations, epochs=3)\n",
        "\n",
        "    # 5. Делаем предсказания\n",
        "    predictions = predict_with_model(text[:512], model, tokenizer)\n",
        "\n",
        "    # 6. Выводим результаты\n",
        "    print(\"Предсказания модели WikiNeural (первые 20 токенов):\")\n",
        "    for token, label in predictions[:20]:\n",
        "        print(f\"{token} -> {label}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    url = \"https://amulex.ru/daily/news/vozrozhdenie-lyutovolkov-iz-igry-prestolov-nauchnyj-proryv-bjfj4kf/?ysclid=mae5l3wify323318294\"  # Пример URL\n",
        "    main(url)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "hb8_BoioyWm_",
      "metadata": {
        "id": "hb8_BoioyWm_"
      },
      "source": [
        "# STREAMLIT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9n-2UEIKexMC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9n-2UEIKexMC",
        "outputId": "fca2953c-aea7-42ca-894c-3cbbda58eedd",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.45.0-py3-none-any.whl.metadata (8.9 kB)\n",
            "Collecting blinker\n",
            "  Downloading blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
            "Collecting altair<6,>=4.0 (from streamlit)\n",
            "  Downloading altair-5.5.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting cachetools<6,>=4.0 (from streamlit)\n",
            "  Downloading cachetools-5.5.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting click<9,>=7.0 (from streamlit)\n",
            "  Downloading click-8.2.0-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting numpy<3,>=1.23 (from streamlit)\n",
            "  Downloading numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting packaging<25,>=20 (from streamlit)\n",
            "  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting pandas<3,>=1.4.0 (from streamlit)\n",
            "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pillow<12,>=7.1.0 (from streamlit)\n",
            "  Downloading pillow-11.2.1-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (8.9 kB)\n",
            "Collecting protobuf<7,>=3.20 (from streamlit)\n",
            "  Downloading protobuf-6.30.2-cp39-abi3-manylinux2014_x86_64.whl.metadata (593 bytes)\n",
            "Collecting pyarrow>=7.0 (from streamlit)\n",
            "  Downloading pyarrow-20.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting requests<3,>=2.27 (from streamlit)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting tenacity<10,>=8.1.0 (from streamlit)\n",
            "  Downloading tenacity-9.1.2-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting toml<2,>=0.10.1 (from streamlit)\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting typing-extensions<5,>=4.4.0 (from streamlit)\n",
            "  Downloading typing_extensions-4.13.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting tornado<7,>=6.0.3 (from streamlit)\n",
            "  Downloading tornado-6.4.2-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.5 kB)\n",
            "Collecting jinja2 (from altair<6,>=4.0->streamlit)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting jsonschema>=3.0 (from altair<6,>=4.0->streamlit)\n",
            "  Downloading jsonschema-4.23.0-py3-none-any.whl.metadata (7.9 kB)\n",
            "Collecting narwhals>=1.14.2 (from altair<6,>=4.0->streamlit)\n",
            "  Downloading narwhals-1.38.2-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting python-dateutil>=2.8.2 (from pandas<3,>=1.4.0->streamlit)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas<3,>=1.4.0->streamlit)\n",
            "  Downloading pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas<3,>=1.4.0->streamlit)\n",
            "  Downloading tzdata-2025.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.27->streamlit)\n",
            "  Downloading charset_normalizer-3.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
            "Collecting idna<4,>=2.5 (from requests<3,>=2.27->streamlit)\n",
            "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.27->streamlit)\n",
            "  Downloading urllib3-2.4.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests<3,>=2.27->streamlit)\n",
            "  Downloading certifi-2025.4.26-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->altair<6,>=4.0->streamlit)\n",
            "  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting attrs>=22.2.0 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
            "  Downloading attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
            "  Downloading jsonschema_specifications-2025.4.1-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting referencing>=0.28.4 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
            "  Downloading referencing-0.36.2-py3-none-any.whl.metadata (2.8 kB)\n",
            "Collecting rpds-py>=0.7.1 (from jsonschema>=3.0->altair<6,>=4.0->streamlit)\n",
            "  Downloading rpds_py-0.24.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.1 kB)\n",
            "Collecting six>=1.5 (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit)\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Downloading streamlit-1.45.0-py3-none-any.whl (9.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/9.9 MB\u001b[0m \u001b[31m98.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
            "Downloading altair-5.5.0-py3-none-any.whl (731 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.2/731.2 kB\u001b[0m \u001b[31m41.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading cachetools-5.5.2-py3-none-any.whl (10 kB)\n",
            "Downloading click-8.2.0-py3-none-any.whl (102 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.2/102.2 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.6/207.6 kB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m120.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m116.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-11.2.1-cp311-cp311-manylinux_2_28_x86_64.whl (4.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m115.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-6.30.2-cp39-abi3-manylinux2014_x86_64.whl (316 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m316.2/316.2 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-20.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (42.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tenacity-9.1.2-py3-none-any.whl (28 kB)\n",
            "Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Downloading tornado-6.4.2-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (437 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m437.2/437.2 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading typing_extensions-4.13.2-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.8/45.8 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading certifi-2025.4.26-py3-none-any.whl (159 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m159.6/159.6 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading charset_normalizer-3.4.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.3/147.3 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonschema-4.23.0-py3-none-any.whl (88 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.5/88.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading narwhals-1.38.2-py3-none-any.whl (338 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m338.4/338.4 kB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m509.2/509.2 kB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tzdata-2025.2-py2.py3-none-any.whl (347 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m347.8/347.8 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading urllib3-2.4.0-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.7/128.7 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading attrs-25.3.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.8/63.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jsonschema_specifications-2025.4.1-py3-none-any.whl (18 kB)\n",
            "Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Downloading referencing-0.36.2-py3-none-any.whl (26 kB)\n",
            "Downloading rpds_py-0.24.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (389 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m389.4/389.4 kB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: pytz, watchdog, urllib3, tzdata, typing-extensions, tornado, toml, tenacity, smmap, six, rpds-py, pyarrow, protobuf, pillow, packaging, numpy, narwhals, MarkupSafe, idna, click, charset-normalizer, certifi, cachetools, blinker, attrs, requests, referencing, python-dateutil, jinja2, gitdb, pydeck, pandas, jsonschema-specifications, gitpython, jsonschema, altair, streamlit\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "tensorflow-metadata 1.17.1 requires protobuf<6.0.0,>=4.25.2; python_version >= \"3.11\", but you have protobuf 6.30.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-3.0.2 altair-5.5.0 attrs-25.3.0 blinker-1.9.0 cachetools-5.5.2 certifi-2025.4.26 charset-normalizer-3.4.2 click-8.2.0 gitdb-4.0.12 gitpython-3.1.44 idna-3.10 jinja2-3.1.6 jsonschema-4.23.0 jsonschema-specifications-2025.4.1 narwhals-1.38.2 numpy-2.2.5 packaging-24.2 pandas-2.2.3 pillow-11.2.1 protobuf-6.30.2 pyarrow-20.0.0 pydeck-0.9.1 python-dateutil-2.9.0.post0 pytz-2025.2 referencing-0.36.2 requests-2.32.3 rpds-py-0.24.0 six-1.17.0 smmap-5.0.2 streamlit-1.45.0 tenacity-9.1.2 toml-0.10.2 tornado-6.4.2 typing-extensions-4.13.2 tzdata-2025.2 urllib3-2.4.0 watchdog-6.0.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "certifi",
                  "charset_normalizer",
                  "dateutil",
                  "markupsafe",
                  "pyarrow",
                  "pytz",
                  "requests",
                  "six",
                  "tornado"
                ]
              },
              "id": "baad5c2e19f6424fb016a68ce9d3af3b"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "pip install streamlit --ignore-installed blinker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "LJ5okGncxCoS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "LJ5okGncxCoS",
        "outputId": "12fc1115-3125-4baa-95bb-909b1dedee8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: streamlit in /usr/local/lib/python3.11/dist-packages (1.45.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cpu)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.2.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.5)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (24.2)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (2.2.3)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (11.2.1)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.30.2)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (20.0.0)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.2)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\n",
            "Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.9.1)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.4.26)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.38.2)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        " pip install streamlit transformers torch beautifulsoup4 requests"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "MWoVRiRICxLi",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MWoVRiRICxLi",
        "outputId": "c6bd80ea-892d-433d-829d-940fb161f894"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-05-11 10:53:35.948 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-11 10:53:35.949 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-11 10:53:36.050 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2025-05-11 10:53:36.051 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-11 10:53:36.052 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-11 10:53:36.052 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-11 10:53:36.053 No runtime found, using MemoryCacheStorageManager\n",
            "2025-05-11 10:53:36.055 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-11 10:53:36.056 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-11 10:53:36.056 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-11 10:53:36.056 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-11 10:53:36.057 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-11 10:53:36.057 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-11 10:53:36.058 Session state does not function when running a script without `streamlit run`\n",
            "2025-05-11 10:53:36.059 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-11 10:53:36.059 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-11 10:53:36.060 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-11 10:53:36.060 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-11 10:53:36.060 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-11 10:53:36.061 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-11 10:53:36.061 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-11 10:53:36.062 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-11 10:53:36.062 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-11 10:53:36.063 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-11 10:53:36.063 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
            "2025-05-11 10:53:36.063 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
          ]
        }
      ],
      "source": [
        "import streamlit as st\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "import torch\n",
        "import os\n",
        "\n",
        "# Настройки страницы\n",
        "st.set_page_config(\n",
        "    page_title=\"NER со SBER AI\",\n",
        "    page_icon=\":mag:\",\n",
        "    layout=\"wide\"\n",
        ")\n",
        "\n",
        "# Заголовок приложения\n",
        "st.title(\"Извлечение именованных сущностей (NER) с Qwen\")\n",
        "st.markdown(\"\"\"\n",
        "Это приложение анализирует текст с веб-страницы и извлекает именованные сущности с помощью модели Qwen.\n",
        "\"\"\")\n",
        "\n",
        "# Функция для получения текста с сайта\n",
        "@st.cache_data(show_spinner=False)\n",
        "def get_website_text(url):\n",
        "    try:\n",
        "        headers = {\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'\n",
        "        }\n",
        "        response = requests.get(url, headers=headers, timeout=10)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Удаляем ненужные элементы\n",
        "        for element in soup(['script', 'style', 'meta', 'link', 'nav', 'footer']):\n",
        "            element.decompose()\n",
        "\n",
        "        return ' '.join(soup.stripped_strings)\n",
        "    except Exception as e:\n",
        "        st.error(f\"Ошибка при получении текста: {e}\")\n",
        "        return None\n",
        "\n",
        "# Загрузка модели с индикатором прогресса\n",
        "@st.cache_resource(show_spinner=\"Загрузка модели...\")\n",
        "def load_model():\n",
        "    model_name = \"sberbank-ai/ruBert-large\" # или \"Qwen/Qwen2.5-32B-Instruct\"\n",
        "    try:\n",
        "        tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "        tokenizer.pad_token = tokenizer.eos_token\n",
        "        model = AutoModelForCausalLM.from_pretrained(model_name)\n",
        "        return tokenizer, model\n",
        "    except Exception as e:\n",
        "        st.error(f\"Ошибка загрузки модели: {e}\")\n",
        "        return None, None\n",
        "\n",
        "# Основной интерфейс\n",
        "def main():\n",
        "    # Сайдбар с настройками\n",
        "    with st.sidebar:\n",
        "        st.header(\"Настройки\")\n",
        "        url = st.text_input(\n",
        "            \"Введите URL страницы:\",\n",
        "            value=\"https://amulex.ru/daily/news/vozrozhdenie-lyutovolkov-iz-igry-prestolov-nauchnyj-proryv-bjfj4kf/?ysclid=mae5l3wify323318294\"\n",
        "        )\n",
        "        max_length = st.slider(\"Максимальная длина текста:\", 100, 2000, 512)\n",
        "        analyze_button = st.button(\"Анализировать текст\")\n",
        "\n",
        "    if analyze_button and url:\n",
        "        with st.spinner(\"Получаем текст с сайта...\"):\n",
        "            text = get_website_text(url)\n",
        "\n",
        "        if text:\n",
        "            # Обрезаем текст до выбранной длины\n",
        "            text = text[:max_length]\n",
        "\n",
        "            st.subheader(\"Извлеченный текст\")\n",
        "            st.text_area(\"Текст\", text, height=200)\n",
        "\n",
        "            with st.spinner(\"Анализируем текст...\"):\n",
        "                tokenizer, model = load_model()\n",
        "\n",
        "                if model:\n",
        "                    # Токенизация и предсказание\n",
        "                    inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True)\n",
        "\n",
        "                    with torch.no_grad():\n",
        "                        outputs = model(**inputs)\n",
        "\n",
        "                    # Получаем предсказания\n",
        "                    predictions = torch.argmax(outputs.logits, dim=-1)\n",
        "                    predicted_tokens = tokenizer.batch_decode(predictions[0])\n",
        "\n",
        "                    # Отображаем результаты\n",
        "                    st.subheader(\"Результаты анализа\")\n",
        "\n",
        "                    col1, col2 = st.columns(2)\n",
        "\n",
        "                    with col1:\n",
        "                        st.markdown(\"**Оригинальные токены:**\")\n",
        "                        st.write(tokenizer.tokenize(text)[:50])  # Показываем первые 50 токенов\n",
        "\n",
        "                    with col2:\n",
        "                        st.markdown(\"**Предсказанные токены:**\")\n",
        "                        st.write(predicted_tokens[:50])\n",
        "\n",
        "                    # Дополнительная информация\n",
        "                    with st.expander(\"Технические детали\"):\n",
        "                        st.write(f\"Размер модели: {sum(p.numel() for p in model.parameters()):,} параметров\")\n",
        "                        st.write(f\"Длина входного текста: {len(text)} символов\")\n",
        "                        st.write(f\"Количество токенов: {inputs.input_ids.shape[1]}\")\n",
        "                else:\n",
        "                    st.error(\"Не удалось загрузить модель\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "p4m_keqjFzkq",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4m_keqjFzkq",
        "outputId": "8d71ccf7-8fff-4315-8c8f-34e8391c2297"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.224.229.246:8501\u001b[0m\n",
            "\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!streamlit run /usr/local/lib/python3.11/dist-packages/colab_kernel_launcher.py [ARGUMENTS]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "NzUhkQD0ZsJk",
      "metadata": {
        "id": "NzUhkQD0ZsJk"
      },
      "source": [
        "# FASTAPI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "TkTmPGz4yomg",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TkTmPGz4yomg",
        "outputId": "7e79e941-20d3-41f7-e95c-c8153413070f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting fastapi\n",
            "  Downloading fastapi-0.115.12-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting uvicorn\n",
            "  Downloading uvicorn-0.34.2-py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (4.13.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\n",
            "Collecting starlette<0.47.0,>=0.40.0 (from fastapi)\n",
            "  Downloading starlette-0.46.2-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from fastapi) (2.11.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi) (4.13.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (8.1.8)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.11/dist-packages (from uvicorn) (0.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.4.26)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4) (2.7)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.0)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.11/dist-packages (from starlette<0.47.0,>=0.40.0->fastapi) (4.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (1.3.1)\n",
            "Downloading fastapi-0.115.12-py3-none-any.whl (95 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m95.2/95.2 kB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.34.2-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.46.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uvicorn, starlette, fastapi\n",
            "Successfully installed fastapi-0.115.12 starlette-0.46.2 uvicorn-0.34.2\n"
          ]
        }
      ],
      "source": [
        "pip install fastapi uvicorn requests beautifulsoup4 torch transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3pAdSbOqAEYx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "3pAdSbOqAEYx",
        "outputId": "8d23b488-f85d-4a9d-d625-d3f3e235a3e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.7-py3-none-any.whl.metadata (9.4 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.7-py3-none-any.whl (23 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.7\n"
          ]
        }
      ],
      "source": [
        "pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_k-VOm2dF2OC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_k-VOm2dF2OC",
        "outputId": "be6b0c00-2cef-4b2d-9f74-f0f7a19e83ee"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Error loading model: Repo id must use alphanumeric chars or '-', '_', '.', '--' and '..' are forbidden, '-' and '.' cannot start or end the name, max length is 96: './qwen_ner'.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:     Will watch for changes in these directories: ['/content']\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n",
            "INFO:     Started reloader process [1901] using StatReload\n",
            "INFO:     Stopping reloader process [1901]\n"
          ]
        }
      ],
      "source": [
        "from fastapi import FastAPI, HTTPException\n",
        "from pydantic import BaseModel\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForTokenClassification\n",
        "from typing import List, Dict, Optional\n",
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import uvicorn\n",
        "from pyngrok import ngrok\n",
        "\n",
        "app = FastAPI(title=\"NER with Qwen\", version=\"1.0\")\n",
        "\n",
        "# Конфигурация\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "MODEL_PATH = \"./qwen_ner\"  # Путь к сохраненной модели\n",
        "\n",
        "# Загрузка модели и токенизатора\n",
        "try:\n",
        "    tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH)\n",
        "    model = AutoModelForTokenClassification.from_pretrained(MODEL_PATH).to(DEVICE)\n",
        "    print(\"Model loaded successfully\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model: {e}\")\n",
        "    model = None\n",
        "    tokenizer = None\n",
        "\n",
        "class TextRequest(BaseModel):\n",
        "    text: str\n",
        "    return_entities: Optional[bool] = True\n",
        "\n",
        "class URLRequest(BaseModel):\n",
        "    url: str\n",
        "    return_entities: Optional[bool] = True\n",
        "\n",
        "class Entity(BaseModel):\n",
        "    word: str\n",
        "    entity: str\n",
        "    start: int\n",
        "    end: int\n",
        "\n",
        "class NERResponse(BaseModel):\n",
        "    tokens: List[str]\n",
        "    labels: List[str]\n",
        "    entities: Optional[List[Entity]] = None\n",
        "    model: str = \"Qwen-NER\"\n",
        "\n",
        "def extract_text_from_url(url: str) -> str:\n",
        "    \"\"\"Извлекает текст с веб-страницы по URL.\"\"\"\n",
        "    try:\n",
        "        headers = {\n",
        "            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.3'}\n",
        "        response = requests.get(url, headers=headers, timeout=10)\n",
        "        response.raise_for_status()\n",
        "        soup = BeautifulSoup(response.text, 'html.parser')\n",
        "\n",
        "        # Удаляем ненужные элементы\n",
        "        for element in soup([\"script\", \"style\", \"nav\", \"footer\", \"head\", \"meta\"]):\n",
        "            element.decompose()\n",
        "\n",
        "        text = soup.get_text(separator=' ', strip=True)\n",
        "        return text\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=400, detail=f\"Error extracting text from URL: {str(e)}\")\n",
        "\n",
        "def predict_entities(text: str) -> NERResponse:\n",
        "    \"\"\"Делает предсказания NER для текста.\"\"\"\n",
        "    if model is None or tokenizer is None:\n",
        "        raise HTTPException(status_code=503, detail=\"Model not loaded\")\n",
        "\n",
        "    try:\n",
        "        # Токенизация и предсказание\n",
        "        inputs = tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True).to(DEVICE)\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**inputs)\n",
        "\n",
        "        # Обработка результатов\n",
        "        predictions = torch.argmax(outputs.logits, dim=2)\n",
        "        tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
        "        labels = [model.config.id2label[p.item()] for p in predictions[0]]\n",
        "\n",
        "        # Собираем сущности\n",
        "        entities = []\n",
        "        current_entity = None\n",
        "\n",
        "        for i, (token, label) in enumerate(zip(tokens, labels)):\n",
        "            if label.startswith(\"B-\"):\n",
        "                if current_entity:\n",
        "                    entities.append(current_entity)\n",
        "                current_entity = {\n",
        "                    \"word\": token,\n",
        "                    \"entity\": label[2:],\n",
        "                    \"start\": i,\n",
        "                    \"end\": i\n",
        "                }\n",
        "            elif label.startswith(\"I-\") and current_entity and label[2:] == current_entity[\"entity\"]:\n",
        "                current_entity[\"word\"] += \" \" + token\n",
        "                current_entity[\"end\"] = i\n",
        "            else:\n",
        "                if current_entity:\n",
        "                    entities.append(current_entity)\n",
        "                    current_entity = None\n",
        "\n",
        "        if current_entity:\n",
        "            entities.append(current_entity)\n",
        "\n",
        "        # Преобразуем сущности в формат с позициями в тексте\n",
        "        char_pos = 0\n",
        "        text_entities = []\n",
        "        offset_mapping = inputs[\"offset_mapping\"][0].cpu().numpy()\n",
        "\n",
        "        for entity in entities:\n",
        "            start_token, end_token = entity[\"start\"], entity[\"end\"]\n",
        "            start_pos = offset_mapping[start_token][0].item()\n",
        "            end_pos = offset_mapping[end_token][1].item()\n",
        "\n",
        "            text_entities.append(Entity(\n",
        "                word=entity[\"word\"],\n",
        "                entity=entity[\"entity\"],\n",
        "                start=start_pos,\n",
        "                end=end_pos\n",
        "            ))\n",
        "\n",
        "        return NERResponse(\n",
        "            tokens=tokens,\n",
        "            labels=labels,\n",
        "            entities=text_entities\n",
        "        )\n",
        "    except Exception as e:\n",
        "        raise HTTPException(status_code=500, detail=f\"Prediction error: {str(e)}\")\n",
        "\n",
        "@app.post(\"/predict/text\", response_model=NERResponse)\n",
        "async def predict_from_text(request: TextRequest):\n",
        "    \"\"\"API endpoint для обработки текста.\"\"\"\n",
        "    result = predict_entities(request.text)\n",
        "    if not request.return_entities:\n",
        "        result.entities = None\n",
        "    return result\n",
        "\n",
        "@app.post(\"/predict/url\", response_model=NERResponse)\n",
        "async def predict_from_url(request: URLRequest):\n",
        "    \"\"\"API endpoint для обработки URL.\"\"\"\n",
        "    text = extract_text_from_url(request.url)\n",
        "    result = predict_entities(text)\n",
        "    if not request.return_entities:\n",
        "        result.entities = None\n",
        "    return result\n",
        "\n",
        "@app.get(\"/health\")\n",
        "async def health_check():\n",
        "    \"\"\"Проверка статуса сервиса.\"\"\"\n",
        "    return {\n",
        "        \"status\": \"OK\" if model and tokenizer else \"Error\",\n",
        "        \"device\": str(DEVICE),\n",
        "        \"model_loaded\": bool(model)\n",
        "    }\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    uvicorn.run(\"__main__:app\", host=\"0.0.0.0\", port=8000, reload=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Rlvv7txQA6qs",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Rlvv7txQA6qs",
        "outputId": "8027e6a2-d419-45b5-d00d-d5da52506b7a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fastapi[standard] in /usr/local/lib/python3.11/dist-packages (0.115.12)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]) (0.46.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]) (2.11.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]) (4.13.2)\n",
            "Collecting fastapi-cli>=0.0.5 (from fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard])\n",
            "  Downloading fastapi_cli-0.0.7-py3-none-any.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]) (0.28.1)\n",
            "Requirement already satisfied: jinja2>=3.1.5 in /usr/local/lib/python3.11/dist-packages (from fastapi[standard]) (3.1.6)\n",
            "Collecting python-multipart>=0.0.18 (from fastapi[standard])\n",
            "  Downloading python_multipart-0.0.20-py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting email-validator>=2.0.0 (from fastapi[standard])\n",
            "  Downloading email_validator-2.2.0-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: uvicorn>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]) (0.34.2)\n",
            "Collecting dnspython>=2.0.0 (from email-validator>=2.0.0->fastapi[standard])\n",
            "  Downloading dnspython-2.7.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: idna>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from email-validator>=2.0.0->fastapi[standard]) (3.10)\n",
            "Requirement already satisfied: typer>=0.12.3 in /usr/local/lib/python3.11/dist-packages (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]) (0.15.3)\n",
            "Collecting rich-toolkit>=0.11.1 (from fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard])\n",
            "  Downloading rich_toolkit-0.14.5-py3-none-any.whl.metadata (999 bytes)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->fastapi[standard]) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->fastapi[standard]) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.23.0->fastapi[standard]) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.23.0->fastapi[standard]) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2>=3.1.5->fastapi[standard]) (3.0.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi[standard]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi[standard]) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi[standard]) (0.4.0)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from uvicorn>=0.12.0->uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]) (8.1.8)\n",
            "Collecting httptools>=0.6.3 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard])\n",
            "  Downloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.6 kB)\n",
            "Collecting python-dotenv>=0.13 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard])\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]) (6.0.2)\n",
            "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard])\n",
            "  Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Collecting watchfiles>=0.13 (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard])\n",
            "  Downloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: websockets>=10.4 in /usr/local/lib/python3.11/dist-packages (from uvicorn[standard]>=0.12.0; extra == \"standard\"->fastapi[standard]) (15.0.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.23.0->fastapi[standard]) (1.3.1)\n",
            "Requirement already satisfied: rich>=13.7.1 in /usr/local/lib/python3.11/dist-packages (from rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]) (13.9.4)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer>=0.12.3->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]) (1.5.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=13.7.1->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.1->rich-toolkit>=0.11.1->fastapi-cli>=0.0.5->fastapi-cli[standard]>=0.0.5; extra == \"standard\"->fastapi[standard]) (0.1.2)\n",
            "Downloading email_validator-2.2.0-py3-none-any.whl (33 kB)\n",
            "Downloading fastapi_cli-0.0.7-py3-none-any.whl (10 kB)\n",
            "Downloading python_multipart-0.0.20-py3-none-any.whl (24 kB)\n",
            "Downloading dnspython-2.7.0-py3-none-any.whl (313 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.6/313.6 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httptools-0.6.4-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (459 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading rich_toolkit-0.14.5-py3-none-any.whl (24 kB)\n",
            "Downloading uvloop-0.21.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchfiles-1.0.5-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (454 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: uvloop, python-multipart, python-dotenv, httptools, dnspython, watchfiles, email-validator, rich-toolkit, fastapi-cli\n",
            "Successfully installed dnspython-2.7.0 email-validator-2.2.0 fastapi-cli-0.0.7 httptools-0.6.4 python-dotenv-1.1.0 python-multipart-0.0.20 rich-toolkit-0.14.5 uvloop-0.21.0 watchfiles-1.0.5\n"
          ]
        }
      ],
      "source": [
        "pip install \"fastapi[standard]\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "egpHitQzyzkB",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egpHitQzyzkB",
        "outputId": "d3ab4519-ce27-4035-c678-2a8c3f904455"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "curl: (7) Failed to connect to localhost port 8000 after 0 ms: Connection refused\n"
          ]
        }
      ],
      "source": [
        "# примеры запросов, обработка текста\n",
        "!curl -X POST \"http://localhost:8000/predict/url\" \\\n",
        "-H \"Content-Type: application/json\" \\\n",
        "-d '{\"url\": \"https://ru.wikipedia.org/wiki/История_Google\", \"return_entities\": true}'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Os_Qd-vlyzUs",
      "metadata": {
        "id": "Os_Qd-vlyzUs"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "gpuType": "V28",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "f1fe27e3860c4cf380107fb67d43e2f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_415f1d3040fb4902aeb231047ac7fa70",
              "IPY_MODEL_307a489504ef401a9ac97224e10a66bc",
              "IPY_MODEL_28a71f72e8b54221a4af5863f5e8597b"
            ],
            "layout": "IPY_MODEL_0b98f7417dff428fbba978a6307ced56"
          }
        },
        "415f1d3040fb4902aeb231047ac7fa70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3be9576eebf46fba1eab3d0384a8a80",
            "placeholder": "​",
            "style": "IPY_MODEL_4eb63505ad5d4248987bc9d1ee304069",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "307a489504ef401a9ac97224e10a66bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fbcd4e8cb8ab48d69d2c8f28f01ed159",
            "max": 17,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_321ffc2d757443b48e6988788de84f6e",
            "value": 17
          }
        },
        "28a71f72e8b54221a4af5863f5e8597b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_018b70395c624efc8e80139ce7dacd21",
            "placeholder": "​",
            "style": "IPY_MODEL_35b504a135fb4f62b5e4fa02779a8e8a",
            "value": " 17/17 [01:44&lt;00:00,  5.33s/it]"
          }
        },
        "0b98f7417dff428fbba978a6307ced56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3be9576eebf46fba1eab3d0384a8a80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4eb63505ad5d4248987bc9d1ee304069": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fbcd4e8cb8ab48d69d2c8f28f01ed159": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "321ffc2d757443b48e6988788de84f6e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "018b70395c624efc8e80139ce7dacd21": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "35b504a135fb4f62b5e4fa02779a8e8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f54e4d3884ba4a57bd73250829bc847c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_616ad4369cd44c05b153348ef75afa03",
              "IPY_MODEL_9789c43ca0b240cebae1bcce30a3123a",
              "IPY_MODEL_dcbac5a2a6a64ac5bba98e9e3666b004"
            ],
            "layout": "IPY_MODEL_cbe2a17997ee404a86aab46125c8dfe1"
          }
        },
        "616ad4369cd44c05b153348ef75afa03": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_50742a2950bb45e1afd1093a9c0cf87c",
            "placeholder": "​",
            "style": "IPY_MODEL_c19bd44538ed44f5a28f15816e6f5da0",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "9789c43ca0b240cebae1bcce30a3123a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4d23905912f4407b8e01b07437e5c1e",
            "max": 264,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_287f20ab102949c0abefb38d27636e46",
            "value": 264
          }
        },
        "dcbac5a2a6a64ac5bba98e9e3666b004": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2143b5e42f3b45be80b41300d7a3e67a",
            "placeholder": "​",
            "style": "IPY_MODEL_5c9687d8faba40cd8b618e3e8165f5c4",
            "value": " 264/264 [00:00&lt;00:00, 32.2kB/s]"
          }
        },
        "cbe2a17997ee404a86aab46125c8dfe1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50742a2950bb45e1afd1093a9c0cf87c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c19bd44538ed44f5a28f15816e6f5da0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b4d23905912f4407b8e01b07437e5c1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "287f20ab102949c0abefb38d27636e46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2143b5e42f3b45be80b41300d7a3e67a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c9687d8faba40cd8b618e3e8165f5c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f0a483742d647c69bcedd51b02aab8f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e553f2385c8344478983af89e900cdfd",
              "IPY_MODEL_21fe7692bd764ec7bd132b303109111f",
              "IPY_MODEL_ba0260793b81403c9563435181511509"
            ],
            "layout": "IPY_MODEL_a971c74f4c70483e8a625876f8766d61"
          }
        },
        "e553f2385c8344478983af89e900cdfd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3236349132c449df9d9bad5bcdfd4d29",
            "placeholder": "​",
            "style": "IPY_MODEL_1bab2ea7fa0c4d53aeb79883dcfef27a",
            "value": "vocab.txt: 100%"
          }
        },
        "21fe7692bd764ec7bd132b303109111f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_453e83b2bb6848dea06a24c1137f1974",
            "max": 995526,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_895fd79f1e21402b91ec9171fb5d5356",
            "value": 995526
          }
        },
        "ba0260793b81403c9563435181511509": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f9fdb6ecbe74a99ba56fb9ec2010bc2",
            "placeholder": "​",
            "style": "IPY_MODEL_02bb8370c8844fbca9e18f9cb46f7d4f",
            "value": " 996k/996k [00:00&lt;00:00, 13.9MB/s]"
          }
        },
        "a971c74f4c70483e8a625876f8766d61": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3236349132c449df9d9bad5bcdfd4d29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1bab2ea7fa0c4d53aeb79883dcfef27a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "453e83b2bb6848dea06a24c1137f1974": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "895fd79f1e21402b91ec9171fb5d5356": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6f9fdb6ecbe74a99ba56fb9ec2010bc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02bb8370c8844fbca9e18f9cb46f7d4f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f2ee1a362f8649938176c5d574a67d0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1d66730e1e494b0da0ad8964c4ea6bf9",
              "IPY_MODEL_ac1daad9f4ad4648a26b07b8fde85e62",
              "IPY_MODEL_b181b4643e9640deb1e8154a12a1071c"
            ],
            "layout": "IPY_MODEL_d249608531c3429686f845be72a2700d"
          }
        },
        "1d66730e1e494b0da0ad8964c4ea6bf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ba5b3b09ff5479c8a938ca6f016d3d3",
            "placeholder": "​",
            "style": "IPY_MODEL_44da238043914997b1343ca5f31fe844",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "ac1daad9f4ad4648a26b07b8fde85e62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f58fd155914540d1bb8a708d0e731984",
            "max": 112,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f3a6c99acd7c4f658d1c26b6562dc2d2",
            "value": 112
          }
        },
        "b181b4643e9640deb1e8154a12a1071c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aa0b38f506da4155b66e7543b1630c8e",
            "placeholder": "​",
            "style": "IPY_MODEL_c6f3e3f0501b43aab97da34166ee9e26",
            "value": " 112/112 [00:00&lt;00:00, 16.7kB/s]"
          }
        },
        "d249608531c3429686f845be72a2700d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4ba5b3b09ff5479c8a938ca6f016d3d3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44da238043914997b1343ca5f31fe844": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f58fd155914540d1bb8a708d0e731984": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3a6c99acd7c4f658d1c26b6562dc2d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "aa0b38f506da4155b66e7543b1630c8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6f3e3f0501b43aab97da34166ee9e26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d6184576c1f649a3bb70b22bd6c41e0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_68aa0b39e9804b7094c8cef8d8340ab5",
              "IPY_MODEL_f3929abeea6b49a0a01a32c40d8d6aba",
              "IPY_MODEL_9cddc9daea944560aa37540e40fcb4ed"
            ],
            "layout": "IPY_MODEL_2a90e034a81b438387e05b2bda303b2c"
          }
        },
        "68aa0b39e9804b7094c8cef8d8340ab5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ceadcf6233ad425b9bc7d788a53d1f74",
            "placeholder": "​",
            "style": "IPY_MODEL_12762a38b8ea498e8bc46588c50dc9a8",
            "value": "config.json: 100%"
          }
        },
        "f3929abeea6b49a0a01a32c40d8d6aba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e6f51b879e84d81b1ab87275ea1bb08",
            "max": 1105,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0a0c9fe08f4c4e89853021a3e76fceee",
            "value": 1105
          }
        },
        "9cddc9daea944560aa37540e40fcb4ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4cdb71be5a054dfab61a7aa579725339",
            "placeholder": "​",
            "style": "IPY_MODEL_942619f6233248099a60469213f2f56c",
            "value": " 1.10k/1.10k [00:00&lt;00:00, 157kB/s]"
          }
        },
        "2a90e034a81b438387e05b2bda303b2c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ceadcf6233ad425b9bc7d788a53d1f74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12762a38b8ea498e8bc46588c50dc9a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7e6f51b879e84d81b1ab87275ea1bb08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a0c9fe08f4c4e89853021a3e76fceee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4cdb71be5a054dfab61a7aa579725339": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "942619f6233248099a60469213f2f56c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c1daefac5def47afb007ef0e724c028d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4abe5d9474174b5b84972da1eb8e7910",
              "IPY_MODEL_708b415e0e3a40fb94ec36aad5b6d6cd",
              "IPY_MODEL_b045c6c6782e4627816d847e03bf6205"
            ],
            "layout": "IPY_MODEL_4d38b1b204b243818479d73cc76cd8e1"
          }
        },
        "4abe5d9474174b5b84972da1eb8e7910": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_876085e7eb484b088d238056af7013b7",
            "placeholder": "​",
            "style": "IPY_MODEL_5d8d1b1201df44ae8fc217e83fe121c7",
            "value": "model.safetensors: 100%"
          }
        },
        "708b415e0e3a40fb94ec36aad5b6d6cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_57e3b2afba7d48bdb4cf5b8d1a7af858",
            "max": 709106620,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_80d84353f43640afb1978fe067792e47",
            "value": 709106620
          }
        },
        "b045c6c6782e4627816d847e03bf6205": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c6bfecdef9740b7bb51703c68845761",
            "placeholder": "​",
            "style": "IPY_MODEL_64dba4ee1a4e4457a1127652a36d4f41",
            "value": " 709M/709M [00:02&lt;00:00, 240MB/s]"
          }
        },
        "4d38b1b204b243818479d73cc76cd8e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "876085e7eb484b088d238056af7013b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d8d1b1201df44ae8fc217e83fe121c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "57e3b2afba7d48bdb4cf5b8d1a7af858": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80d84353f43640afb1978fe067792e47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6c6bfecdef9740b7bb51703c68845761": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "64dba4ee1a4e4457a1127652a36d4f41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6eb04acf75a14c5a8fb948c3ce2eed6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ea3781060fca4022a5751af068029e8e",
              "IPY_MODEL_746dd2df7cbd420da8c341cfcfd49ae1",
              "IPY_MODEL_ccbe6da0e6624fc382f7e3fb6b3990d9"
            ],
            "layout": "IPY_MODEL_e5043865331a4d27a442754e12d917dd"
          }
        },
        "ea3781060fca4022a5751af068029e8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52af585950744b2ba91214d53dfaddb2",
            "placeholder": "​",
            "style": "IPY_MODEL_1dbb78b204664d1d90f34da67aa6627d",
            "value": "config.json: 100%"
          }
        },
        "746dd2df7cbd420da8c341cfcfd49ae1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a1280cecb332473f9494c68d7866c412",
            "max": 591,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f6853b48bca046109856fcebc6ab2037",
            "value": 591
          }
        },
        "ccbe6da0e6624fc382f7e3fb6b3990d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_291e40a292354dbe9f1ac378e4bd96d4",
            "placeholder": "​",
            "style": "IPY_MODEL_3978fd6387a94b829e646abd79732d49",
            "value": " 591/591 [00:00&lt;00:00, 84.4kB/s]"
          }
        },
        "e5043865331a4d27a442754e12d917dd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52af585950744b2ba91214d53dfaddb2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1dbb78b204664d1d90f34da67aa6627d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1280cecb332473f9494c68d7866c412": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6853b48bca046109856fcebc6ab2037": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "291e40a292354dbe9f1ac378e4bd96d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3978fd6387a94b829e646abd79732d49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f203c48443cd462f911d08ae63000293": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_34d222820996421680d193c5fd564d62",
              "IPY_MODEL_68e5b184f2454aac9bf826241bd7ceb3",
              "IPY_MODEL_1b4b2912953a4180b671edb133f9d70f"
            ],
            "layout": "IPY_MODEL_c846148774804d32937b5557562fa134"
          }
        },
        "34d222820996421680d193c5fd564d62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5ec2aa2eb6149859b622d9db25fa55a",
            "placeholder": "​",
            "style": "IPY_MODEL_76d00e82d86349e2ba8ff5e7782858ca",
            "value": "vocab.txt: 100%"
          }
        },
        "68e5b184f2454aac9bf826241bd7ceb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccc85ee996cb4b458dcb08bd57a65500",
            "max": 1780720,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_624020d0b28a4e8287e681855092935d",
            "value": 1780720
          }
        },
        "1b4b2912953a4180b671edb133f9d70f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a12ebf7a8d84b0e8c71d3691ebffb83",
            "placeholder": "​",
            "style": "IPY_MODEL_82853561892b414190baee66e11c1f73",
            "value": " 1.78M/1.78M [00:00&lt;00:00, 47.8MB/s]"
          }
        },
        "c846148774804d32937b5557562fa134": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5ec2aa2eb6149859b622d9db25fa55a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76d00e82d86349e2ba8ff5e7782858ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ccc85ee996cb4b458dcb08bd57a65500": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "624020d0b28a4e8287e681855092935d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3a12ebf7a8d84b0e8c71d3691ebffb83": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82853561892b414190baee66e11c1f73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f41be0b675b431b8dc03e16f910261c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c404c9b825e9484f855d6722af38d88d",
              "IPY_MODEL_0e47c48fcf8440d78fc739543e56ebe8",
              "IPY_MODEL_406c098bbdc840d09d6545acfec7577c"
            ],
            "layout": "IPY_MODEL_243accb0267049b886fd15fa4bcfb7e1"
          }
        },
        "c404c9b825e9484f855d6722af38d88d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_37b12e9f49f244538128ffad8c267eea",
            "placeholder": "​",
            "style": "IPY_MODEL_4a19727cc8ec47889bcdc399ec9e7ec6",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "0e47c48fcf8440d78fc739543e56ebe8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b7f2ff176b44d7abf84a70a2f18f6a7",
            "max": 1712497782,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_84c1f5040924462eb9240a9341078882",
            "value": 1712497782
          }
        },
        "406c098bbdc840d09d6545acfec7577c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2ace6a6f7c64958afc689921688e1be",
            "placeholder": "​",
            "style": "IPY_MODEL_4baa4bcf86ba44858f9bb349eed2e109",
            "value": " 1.71G/1.71G [00:06&lt;00:00, 245MB/s]"
          }
        },
        "243accb0267049b886fd15fa4bcfb7e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "37b12e9f49f244538128ffad8c267eea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a19727cc8ec47889bcdc399ec9e7ec6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0b7f2ff176b44d7abf84a70a2f18f6a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84c1f5040924462eb9240a9341078882": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c2ace6a6f7c64958afc689921688e1be": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4baa4bcf86ba44858f9bb349eed2e109": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}